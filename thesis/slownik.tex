% !TEX encoding = UTF-8 Unicode

\chapter{Słownik pojęć}
\section{Zbiór danych}
Do realizacji pracy konieczny było stworzenie zbioru danych składającego się z obrazów
z kośćmi do gry. Zdjęcia zostały zrobione kamerą o rozdzielczości 1600x1200 pikseli,
a następnie zmniejszone w celu zaoszczędzenia pamięci i osiągnięcia żądanego rozmiaru,
który ma kluczowe znaczenie w przypadku zastosowań sieci neuronowych.
Oprócz zmniejszenia obrazy były również obracane, przekrzywiane(deformowane? wypaczane? \textit{warping}) oraz kadrowane.
Tak powstałe, liczne zbiory były wykorzystywane w trybie RGB oraz w odcieniach skali szarości,
co pozwoliło na oszczędzenie pamięci przez zmniejszenie liczby kanałów do jednego.\\
W pracy używano zbiorów z obrazami o rozmiarach 64x64 oraz 106x79 pikseli. Każde zdjęcie
w zbiorze miało przypisaną wartość liczbową informującą o faktycznej ilości oczek wyrzuconych
na przedstawionej kostce. Wartość ta zwana jest odpowiedzią i jest wykorzystywana w
procesie uczenia sieci jako docelowa informacja, którą ma zwrócić sieć po weryfikacji danego obrazu.

\paragraph{Zbiór treningowy} \mbox{}\\
Część zbioru danych, która wykorzystywana jest w procesie uczenia sieci określana jest jako zbiór
treningowy lub zbioru uczący. Jego liczebność to zazwyczaj 60-80\% całego zbioru danych.
Praktycznie zawsze dane znajdujące się w tym zbiorze, przed rozpoczęciem uczenia,
poddawane są losowej permutacji.

\paragraph{Zbiór testowy} \mbox{}\\
Do oceny zdolności sieci neuronowej do rozpoznawania danych sluży zbiór testowy, zwany
też walidacyjnym. Celem rozdzielenia tego zbioru od danych testowych jest weryfikacja
sieci na danych, które nie zostały przez nią przetworzone podczas treningu.

\section{Budowa sieci neuronowej}
\paragraph{Sieć neuronowa} \mbox{}\\
Sieć neuronowa \textit{(ang. ANN Artificial Neural Network)} to struktura matematyczna,
składająca się z neuronów połączonych w warstwy, mająca odzwierciedlać działanie
biologicznych sieci neuronowych, a w szczególności mózgu \cite{intuitiveExplanation, WIKIcnn}.
Sieci mają szerokie zastosowanie w bardzo wielu dziedzinach, co przejawia się ich
popularyzacją w ostatnich latach. Wymagają kosztownego obliczeniowo i czasowo
procesu uczenia, podczas którego dostosowują się do danego problemu. Użycie wytrenowanej
sieci, nie wymaga powtarzania uczenia, co pozwala na jej natychmiastowe wykorzystanie.\\
W dziedzinie rozpoznawania obrazów sieci są w stanie zidentyfikować elementy na obrazach,
bez wcześniejszej znajomości lub wiedzy na temat przedmiotu który mają rozpoznać.

\paragraph{Neuron} \mbox{}\\
Neuron jest najmniejszym elementem sieci neuronowej, posiadającym wiele wejść i jedno wyjście \cite{CS231n_activ, NNbiology, NeuronAnimation}.
Z neuronów w poprzednich warstwach, na każde z wejść docieraja sygnały, które mają 
przypisaną wagę. W neuronie obliczana jest suma ważona wejść, od której odejmowana jest
wartość progowa. Jeśli suma przekroczy wartość progową, neuron jest uaktywniany, a suma
przekazywana jest jako argument funkcji aktywacji neuronu na jego wyjście.\\
Poniższy wzór \ref{eq:neuron} przedstawia sumę ważoną wejść neuronu wraz z dodatkową wagą.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:neuron}
f(x_{i}) = f\Big(\sum_{i}w_{i}x_{i} + b \Big)\\
\end{equation}
\caption{Suma ważona w neuronie wraz z dodatkową wagą \textit{b}}
\end{figure}

\paragraph{Wagi neuronu} \mbox{}\\
Jak opisano już wcześniej, neurony połączone są między sobą dzięki licznym wejściom.
Każde takie połączenie ma przypisaną wagę, która zmienia się podczas treningu,
dostosowując sieć neuronową do danych treningowych. Efektem tego jest osiąganie
coraz lepszych wyników w miarę trwania procesu uczenia.

\paragraph{Bias} \mbox{}\\
Bias, użyty już we wzorze \ref{eq:neuron} na sumę wag w neuronie jest dodatkową wagą wejściową,
umożliwiająca jego lepsze dopasowanie neuronu do danych treningowych \cite{needForBias}.

\paragraph{Warstwa} \mbox{}\\
Neurony w sieci zorganizowana są w warstwach. Komunikacja odbywa się tylko między kolejnymi
warstwami, neurony w danej warstwie nie są ze sobą połączone \cite{CS231n, substBigConv}.
Istnieje wiele rodzajów warstw, a sygnał przechodzący przez całą sieć zaczyna się w tzw.
warstwie wejściowej oraz kończy w tzw. warstwie wyjściowej.

\paragraph{Funkcja kosztu} \mbox{}\\
Do porównywania wyników otrzymywanych przez sieć neuronową wykorzystywana jest funkcja kosztu,
funkcja oceniajaca lub funkcja błędu. Jest ona niezbędna do prawidłowego przeprowadzenie
procesu uczenia. Funkcja dostarcza informacje o różnicy między obecnym
stanem sieci, a optymalnym rozwiązaniem dla danych treningowych. Algorytm uczenia
analizuje wartość funkcji kosztu w kolejnych krokach w celu jej zminimalizowania.\\
Najczęściej wykorzystywaną funkcją kosztu jest błąd średniokwadratowy \ref{eq:mse}.
W tej pracy z uwagi na posiadanie 6 możliwych do uzyskania wyników na wyjściu sieci,
zastosowano wielowymiarową entropię krzyżową (\textit{ang. Categorical cross-entropy}) \ref{eq:categorical-crossentropy},
która jest preferowana ponieważ uwypukla aż tak bardzo nieprawidłowych wartości \cite{whyNotMSE}. Jest również
sugerowana przez bibliotekę Keras oraz wykorzystywana w wielu przykładowych modelach sieci neuronowych.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:mse}
J(\eta) = \frac {1}{2} \sum_{i}^{m} \Big(h_{\theta}(x^{(i)}) - y^{(i)} \Big)^2\\
\end{equation}
\caption{Błąd średniokwadratowy}
\end{figure}
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:categorical-crossentropy}
L_{i} = - \sum_{j} t_{i,j} log(p_{i,j})\\
\end{equation}
\centering
gdzie: p - predykcje, t - cele, i - wartość, j - klasa
\caption{Wielowymiarowa entropia krzyżowa}
\end{figure}

\paragraph{Współczynnik uczenia} \mbox{}\\
Aby dostosować stopień w jakim sieć neuronowa będzie dostosowywać się do danych wykorzystujemy
współczynnik lub wskaźnik uczenia się \textit{(ang. lerning rate)}. Często jest
uzależniony od wyboru rodzaju optymalizatora. Wybranie zbyt małego współczynnika wydłuży
proces uczenia, a w skrajnych przypadkach sieć nie zdąży dotrzeć do minimum.
Jeśli zostanie wybrany za duży współczynnik, może spowodować problemy ze znalezieniem
optymalnego rozwiązania. W niektórych algorytmach współczynnik uczenia zmniejsza się w czasie,
by lepiej dostosować się do danych i zniwelować oba wspomniane problemy.

\section{Propagacja wsteczna}
Propagacja wsteczna lub wsteczna propagacja błędów \textit{(ang. Backpropagation)}
jest algorytmem uczenia sieci neuronowych \cite{CS231n_ackprop, backprop}.
Służy do wyliczenia gradientu funkcji kosztu, który informuje o szybkości spadku wartości tej funkcji
w danym kierunku z uwzględnieniem wag neuronów oraz biasu. Obliczenie gradientu w sieci propagowane
jest od warstwy wyjściowej do wejściowe, czemu algorytm zawdzięcza swoją nazwę.

\section{Konwolucyjna sieć neuronowa}

Ilość parametrów przy pracy na zdjęciach jest dużym problemem w przypadku sieci neuronowych.
W celu ich zmniejszenia, stosuje się konwolucyjne sieci neuronowe \textit{(ang. CNN - Convolutuinal Neural Network)}.
Do kolejnych warstw nie są przekazywane informacje o wszystkich pikselach znajdujących się
na obrazach. Zamiast tego, sieć analizuje obraz przy użyciu filtrów konwolucyjnych i
przesyła dalej informacje o zaobserwowanych cechach.

\paragraph{Konwolucja} \mbox{}\\
Konwolucja, inaczej splot polega na złożeniu dwóch funkcji. W przypadku obrazów
jedna z tych funkcji to obraz, który ma rozmiary większe niż druga funkcja określana
mianem filtra konwolucyjnego. Zastosowanie splotu, w zależności od przypadku,
pozwala na rozmycie, wyostrzanie lub wydobycie głębi z danego obrazu \cite{konwolucja}.
Poniższy wzór \ref{eq:conv} przedstawia sposób obliczenia splotu dwóch funkcji.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:conv}
h[m, n] = (f * g)[m, n] = \sum_j^m \sum_k^n f[j, k] * g[m-j, n-k] \\
\end{equation}
\caption{Funkcja h to splot funkcji f oraz g}
\end{figure}

\paragraph{Konwolucyjna sieć neuronowa} \mbox{}\\
Konwolucyjna lub splotowa sieć neuronowa \textit{(ang. CNN - Convolutuinal Neural Network)}
to typ sieci odnoszący największe osiągnięcia w dziedzinie rozpoznawania obrazów,
w wielu przypadkach dorównując lub nawet pokonując ludzkie wyniki. Zawdzięczają to
swojej budowie, która różni się od zwykłych sieci wykorzystaniem warstw konwolucyjnych
i poolingowych, poprzedzających warstwy w pełni połączone. Sieć taka analizuje obraz
przy użyciu filtrów konwolucyjnych, dzięki którym jest w stanie rozpoznawać cechy
obrazów, co znacząco poprawia ich klasyfikacje.

\section{Warstwy sieci neuronowej}
\paragraph{Wejściowa} \mbox{}\\
W pracy, gdzie zbiorami danych są zbiory obrazów, każdy pojedynczy piksel obrazu
odpowiada jednej wartości liczbowej. W związku z tym rozmiar pierwszej warstwy
wejściowej jest identyczny z wymiarami obrazu. Warstwa wejściowa charakteryzuje się
brakiem wejść oraz biasu.

\paragraph{Wyjściowa} \mbox{}\\
Rozmiar warstwy wyjściowej odpowiada ilości klas, do jakiej wejściowe dane miały
zostać sklasyfikowne. Oczekiwanym wyjściem sieci w pracy była liczba oczek możliwych
do wyrzucenia na kostce, co odpowiada 6 klasom, po jednej na każdą wartość na boku
kostki. Wyjściem wszystkkich przedstawianych w tej pracy sieci był wektor o wymiarach
6x1.

\paragraph{Konwolucyjna} \mbox{}\\
Warstwa konwolucyjna służy do przetworzenia danych z poprzedniej warstwy przy użyciu
filtrów konwolucyjnych \cite{CS231n}. Filtry mają określone wymiary i służą do znajdowania cech
na obrazach lub ich fragmentach. Najczęściej spotykanymi przykładami filtrów są
kwadraty o wymiarach 3x3 piksele, które przetwarzają informacje zawarte w 9 pikselach
na jeden piksel wyjściowy.
Zastosowanie wielu warstw konwolucyjnych umożliwia filtrom analizowanie bardziej złożonych
zależności na obrazach i jest określane jako głęboka sieć. Szeroka sieć posiada większą
liczbę neuronów w każdej z warstw, co umożliwia precyzyjniejszą obserwację danych.
Ograniczeniem w przypadku sieci głębokiej i szerokiej jest ilość i czas obliczeń, co
wymusza wybranie kompromisu między ilością warstw i neuronów dla danego problemu.

\paragraph{Aktywacyjna} \mbox{}\\
Jest to wydzielenie funkcji aktywacji do osobnej warstwy, które jest realizowane
w niektórych bibliotekach. Celem takiego zabiegu jest umożliwienie podglądu danych
na wyjściu neuronu, tuż przed zaaplikowaniem samej funkcji aktywacji.

\paragraph{W pełni połączona} \mbox{}\\
Sieć neuronowa składa się z w pełni połączonych warstw \textit{(ang. Fully Connected, Dense)}.
W konwolucyjnych sieciach neuronowych warstwy te występują po warstwach konwolucyjnych
i służą do powiązania nieliniowych kombinacji, które zostały wygenerowane przez
warstwy konwolucyjne oraz ich sklasyfikowania. Dodatkowo nie wymagają dużych nakładów
obliczeniowych i są stosunkowo proste do zaaplikowania. Swoją nazwę biorą od sposobu, w jaki
realizowane sa połączenia między warstwami. Każdy neuron łączy się ze wszystkimi neuronami
następnej warstwy.

\paragraph{Flatten} \mbox{}\\
Warstwa spłaszczająca \textit{(ang. Flatten)} stosowana jest w celu połączenia warstw
konwolucyjnych lub aktywacji wraz z warstwami w pełni połączonymi. Realizowane jest
to poprzez przekształcenie warstwy wejściowej do jednowymiarowego wektora, który następnie
służy za wejście do kolejnych warstw.

\paragraph{Odrzucająca} \mbox{}\\
Warstwa odrzucająca \textit{(ang. Dropout)} zapobiega przetrenowaniu \textit{(ang. Overfitting)}
sieci \textit{Zapobieganie przetrenowaniu} \cite{DropoutPreventOverfit}.
Proces ten polega na nie wykorzystywaniu wyjść pewnych neuronów, zarówno
w przypadku przechodzenia w przód oraz w tył \textit{DropConnect} \cite{DropConnect}. Stosuje się ją po warstwach w pełni
połączonych, w celu zapobiegania rozległym zależnościom między neuronami. W warstwie
tej określone jest prawdopodobieństwo \textit{p} z jakim neuron zostanie zachowany
w warstwie oraz \textit{p - 1} z jakim zostanie odrzucony. Najczęstsza wartość jest
z zakresu 0,5-0,8.

\paragraph{Pooling} \mbox{}\\
Warstwa tzw. poolingu wykorzystywana jest do zmniejszenia rozmiaru pamięci oraz ilości obliczeń
wymaganych przez sieć neuronową, jak również może zapobiegać przetrenowaniu \cite{CS231n}. Operacja zmniejszenia
polega na wybraniu jednego piksela z danego obszaru i przekazaniu go dalej. Najczęściej wykorzystywaną
warstwą poolingową jest MaxPooling, wybierający piksel o największej wartości. Obszar, z jakiego
wybieramy dany piksel, zależy od ustawień, najczęściej jest to kwadrat o wymiarach 2x2. Pooling
jest krytykowany, ponieważ nie zachowuje informacji o położeniu piksela przekazanego na wyjście
warstwy, co może objawiać się błędnymi interpretacjami podczas testowania sieci.

\section{Funkcje aktywacji}
\paragraph{Funkcja aktywacji} \mbox{}\\
Przy pomocy funkcji aktywacji obliczana jest wartość wyjściowa neuronów w sieci
neuronowej. Argumentem dostarczanym do funkcji aktywacji jest suma wejść neuronu
pomnożonych przez przypisane im wartości wag. Zależnie od konkretnego rodzaju funkcji
aktywacji, neuron po przekroczeniu danego progu wysyła sygnał wyjściowy, odbierany
przez neurony znajdujące się w następnej warstwie. Jeśli próg nie zostanie przekroczony,
neuro nie wyśle żadnego sygnału.
\begin{equation}
f\Big(\sum_{i}w_{i}x_{i} + b\Big) \\
\end{equation}

\paragraph{Liniowa} \mbox{}\\
Funkcja ta jest praktycznie niewykorzystywana w sieciach neuronowych \cite{activationFunctions}.
Połączenie wielu warstw, których neurony mają liniową funkcję aktywacji można przedstawić
za pomocą jednej warstwy, ponieważ złożenie wielu funkcji liniowych również będzie
funkcją liniową. Nieliniowość funkcji pozwala na klasyfikację danych przechodzących
przez sieć.
\begin{equation}
f(x) = x
\end{equation}

\paragraph{Sigmoid} \mbox{}\\
Największym problemem funkcji sigmoidalnej jest duże ryzyko zaniknięcia gradientu,
co może prowadzić do problemu tzw. umierającego neuronu \textit{Opis Sigmoid} \cite{activationFunctions}.
Zjawisko to ma miejsce, gdy dla danej funkcji aktywacji, gradient staję się bardzo mały, co jest równoznaczne
z zaprzestaniem procesu uczenia. W przypadku tej funkcji gradient może zanikać obustronnie.
\begin{equation}
f(x) = \sigma(x) = \frac{1}{1 + e^{-x}} \\
\end{equation}

\paragraph{Tangens hiperboliczny} \mbox{}\\
Tangens hiperboliczny lub tanh jest w istocie przekształconą funkcją simgodalną
\textit{Opis tanh} \cite{activationFunctions, activationFunctionsV2}. Wykorzystanie
jej powoduje większe wahania gradientu.
\begin{equation}
f(x) = tanh(x) = \frac{(e^x - e^{-x})}{(e^x + e^{-x})} = \frac{2}{1+e^{-2x}} - 1 = 2 sigmoid(2x) - 1\\
\end{equation}

\paragraph{ReLU} \mbox{}\\
ReLU \textit{(and. Rectified linear unit)} jest najpopularniejszą funkcją aktywacji
wykorzystywaną w sieciach neuronowych \textit{Wady i zalety ReLU} \cite{CS231n_activ, WIKIrectifier}.
Zasługą tego jest szybki czas uczenia sieci
bez znaczącego kosztu w postaci generalizacji dokładności. Problem z zanikającym
gradientem jest mniejszy niż w przypadku funkcji sigmoidalnej, ponieważ występuje
on tylko z jednej strony.
\begin{equation}
f(x) = max(0, x)
\end{equation}

\paragraph{LeakyReLU} \mbox{}\\
LeakyReLU jest ulepszeniem ReLU \textit{Wady i zalety LeakyReLU} \cite{CS231n_activ}
dzięki zastosowaniu niewielkiego gradientu w sytuacji, dla której ReLU jest nieaktywne. Zmiana ta pozwala na uniknięcie problemu tzw
umierającego neuronu.
\begin{equation}
f(x) =
\begin{cases}
x & \text{if } x \geqslant 0 \\
0.01x & \text{if } x < 0 \\
\end{cases}
\end{equation}

\section{Optymalizatory}
\paragraph{Optymalizator} \mbox{}\\
Inne określenie algorytmu optymalizacyjnego wykorzystywanego do obliczania wag neuronów
i biasu sieci neuronowej. Posiada kluczowe znaczenie podczas procesu uczenia sieci,
zarówno w kwestii czasu oraz skuteczności. Z tego powodu jest to jeden z kluczowych
obszarów obecnych badań i rozwoju sieci neuronowych \textit{Artykuł na temat optymalizatorów} \cite{typesOfOptimizationAlgorithms}.

\paragraph{Metoda gradientu prostego} \mbox{}\\
Metoda gradientu prostego \textit{(ang. Gradient Descent)} jest podstawowym algorytmem
służacym do uaktualniania wartości wag oraz biasu podczas procesu uczenia sieci. Wadą tej
metody jest przeprowadzanie jednorazowej aktualizacji po wyliczeniu gradientu dla
całego zestawu danych. Jest to bardzo powolne, w niektórych przypadkach może powodować
problem z ilością zajmowanego miejsca w pamięci. Największą wadą jest możliwość doprowadzenia
do stagnacji w jednym z lokalnych minimów funkcji.
\begin{equation}
\theta = \theta - \eta * \nabla J(\theta)
\end{equation}

\paragraph{Stochastic Gradient Descent} \mbox{}\\
\textit{(nazwa w języku angielskim z powodu braku znalezienia polskiego odpowiednika)}
Stochastic Gradient Descent \textit{(skrót. GDA)} jest rozwinięciem metody gradientu
prostego, bardzo często wykorzystywana w praktyce \textit{Opis SGD} \cite{OptimizersOverview}.
Ulepszenie polega na obliczaniu gradientu dla jednego lub niewielkiej ilości przykładów
treningowych. Najczęściej korzysta się z więcej niż jednego przykładu, co zapewnia
lepszą stabilność oraz wykorzystuje zrównoleglenie obliczeń. SGD zapewnia większą rozbieżność
niż metoda gradientu prostego, co umożliwia znajdowanie nowych lokalnych minimów, ale
wiąże się z koniecznością zastosowania mniejszego współczynnika uczenia.
\begin{equation}
\theta = \theta - \eta * \nabla J(\theta; x_i; y_i)
\end{equation}

\paragraph{RMSprop} \mbox{}\\
RMSprop umożliwia obliczanie gradientu dla każdego parametru z osobna i zapobiega
zmniejszaniu się współczynnika uczenia \textit{Opis RMSprop} \cite{RMSpropOptimizer, OptimizersOverview}.
Algorytm dostosowuje współczynnik uczenia dla każdej wagi,
bazując na wielkości jej gradientu.

\paragraph{Adam} \mbox{}\\
Adam to skrót od angielskiej nazwy \textit{Adaptive Moment Estimation} i jest rozwinięciem
metody Stochastic Gradient Descent \textit{Opis metody Adam} \cite{AdamOptimizer, OptimizersOverview}.
Metoda ta pozwala na obliczanie z osobna gradientu dla
każdego parametru oraz każdej zmiany momentum. Zapobiega dodatkowo zmniejszającemu się
wskaźnikowi uczenia, a co najważniejsze jest bardzo szybka i pozwala na sprawne uczenie
się sieci. W tej metodzie oblicza się dwa momenty \textit{m} oraz \textit{v}.
\begin{equation}
\begin{align*}
\hat{m_t} = \frac{m_t} {1 - \beta^t_1}, \\
\hat{v_t} = \frac{v_t} {1 - \beta^t_2}, \\
\end{align*}
\end{equation}
Obliczone momenty podstawiane są do wzoru
\begin{equation}
\theta_{t+1} = \theta_t - \frac {\eta} {\sqrt{\hat{v_t}} + \epsilon} \hat{m_t}
\end{equation}
gdzie najczęściej \textbeta \textsuperscript{t}\textsubscript{1} = 0.9 oraz
\textbeta \textsuperscript{t}\textsubscript{2} = 0.99 a \straightepsilon = 10^{-8}\\

\section{Procesy}

\paragraph{Uczenie} \mbox{}\\
Proces uczenia bądź treningu sieci służy zmianie wartości wag, najczęściej zainicjowanych
pseudolosowymi wartościami oraz biasu. Uczenie sieci neuronowej jest bardzo
kosztowne obliczeniowo, co wręcz uniemożliwiało trenowanie modeli w przeszłości,
a obecnie jest jednym z powodów dużego zainteresowania rozwojem technologicznym kart
graficznych. Operacje dodawania oraz mnożenia wektorów i macierzy wykonywane są miliony razy,
mogą być przyśpieszone dzięki możliwościom zrównoleglenia obliczeń.\\

\paragraph{Epoka} \mbox{}\\
Proces uczenia sieci podzielony jest na epoki. Każda epoka odpowiada przejściu
wszystkich elementów z treningowego zbioru danych przez sieć. Ilość epok, podczas których sieć będzie się uczyć ustala się na co najmniej kilkanaście. W przypadku
większych zbiorów danych lub większych modeli ilość epok jest zwiększana.\\
Często spotykaną praktyką w wielu pracach naukowych jest przedstawianie wyników
dla sieci po 100 epokach treningu.

\paragraph{Testowanie} \mbox{}\\
Model sieci neuronowej poddawany ocenie, dzięki której można określić, w jakim stopniu
prawidłowo rozpoznaje obrazy. W przypadku wytrenowanych modeli istotne jest, aby zbiór służący do
testowania nie był wcześniej użyty do treningu sieci. Nauczony model powinien być w stanie
rozpoznawać nowe, nieużyte podczas procesu uczenia dane i poprawnie je klasyfikować.

\paragraph{Predykcja} \mbox{}\\
Wartości zwrócone przez sieć po umieszczeniu w niej określonych danych są określane
mianem predykcji. Pozwala to na wykorzystanie nauczonego modelu w praktycznym
zastosowaniu.

\section{Inne}

\paragraph{ILSVRC} \mbox{}\\
ImageNet Large Scale Visual Recognition Competition \cite{ILSVRC} to coroczny konkurs organizowany
od 2010 roku, w którym naukowcy walczą o najlepszy wynik w dziedzinie rozpoznawania
obrazów przez skonstruowane przez siebie algorytmy. Sieć AlexNet, na której bazowało
kilka stworzonych sieci neuronowych, została stworzona na potrzeby tego konkursu
w 2012 roku.

\paragraph{MNIST} \mbox{}\\
Baza danych MNIST \cite{MNIST} to zbiór 60000 treningowych i 10000 testowych czarno-białych obrazów
w rozmiarze 28x28x1, zawierających ręcznie napisane cyfry 0-9. Jest jednym z
najpopularniejszych zbiorów służących do rozpoczęcia nauki sztucznych sieci neuronowych
i uczenia maszynowego.

\paragraph{CIFAR-10} \mbox{}\\
Zbiór CIFAR-10 \cite{CIFAR-10} składa się z 50000 treningowych i 10000 testowych kolorowych obrazów w rozmiarze
32x32x2. Jest podzielony na 10 klas: samolot, samochód, ptak, kot, jeleń, pies, żaba,
koń, statek, ciężarówka; gdzie każdej z nich przypada po 6000 obrazów. Jest to podobnie
jak MNIST jeden z najbardziej popularnych zbiorów do uczenia maszynowego i sieci neuronowych.

\\\\\\
Tematy do uwzględnienia:
opis RMSprop,
minibatch,
nesterov,
momentum,
softmax,
categorical crossentropy,
one-hot encoding,
