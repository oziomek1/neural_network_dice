% !TEX encoding = UTF-8 Unicode

\chapter{Słownik pojęć}

\paragraph{Zbiór danych} \mbox{}\\
Zbiór danych lub obrazów to zbiór wszystkich zdjęć kości wykonanych na poczet
pracy z wykorzystaniem kamery. Każde zdjęcie w zbiorze jest przetworzone w celu
zmniejszenia czasu uczenia się sieci oraz potrzebnej pamięci. Zdjęcia były wykonywane
kamerą o rozdzielczości 1600x1200 pikseli. Każde ze zdjeć w zbiorze zostało
poddane procesowi skalowania oraz kadrowania w celu osiągnięcia odpowiedniego
rozmiaru. W celu uzyskania większej liczebności zbioru wszystkie obrazy zostały
dodatkowo poddane operacji obrotu o dany kąt. Każdy ze zbiorów został zduplikowany
i poddany konwersji z trybu RGB na skalę szarości przez usunięcie informacji o barwie
oraz nasyceniu kolorów, pozostawiając jedynie informację o jasności piksela. \\
Po przeprowadzeniu całego procesu, każdy obraz miał wymiary 64x64, zarówno w wersji
kolorowej i czarno białej, co skutkowało rzeczywistymi rozmiarami odpowiednio 64x64x3
oraz 64x64x1.

\paragraph{Zbiór treningowy} \mbox{}\\
Część zbioru danych który wykorzystywany jest w procesie uczenia sieci określany
jest mianem zbioru treningowego lub zbioru uczącego. Jego liczebność to zazwyczaj 60-80\% całego zbioru
danych. Praktycznie we wszystkich zastosowaniach dane w tym zbiorze przed rozpoczęciem
uczenia poddawane są losowej permutacji.

\paragraph{Zbiór testowy} \mbox{}\\
Zbiór testowy lub zbiór walidacyjny służy do oceny zdolności sieci do rozpoznawania
danych. Celem rozdzielenia tego zbioru od danych testowych jest weryfikacja sieci
na danych które wcześniej nie zostały przetworzone przez sieć.

\paragraph{Neuron} \mbox{}\\
Najmniejszy element sieci neuronowej, przyjmuje wiele wejść i jedno wyjście. Może
zawierać także próg (ang. threshold), który może być zmieniony przez funkcje uczącą.
Neuron wyposazony jest także w funkcję aktywacji, odpowiednio modyfikującą jego wyjście.
Każde wyjście neuronu z poprzedniej warstwy połączone jest z wejściami innych neuronów
w warstwie następnej.
\begin{equation}
f(x_{i}) = \sum_{i}w_{i}x_{i} + b \\
\end{equation}

\paragraph{Wagi neuronu} \mbox{}\\
Połączenia w sieci realizowane są między wyjściem poprzedniego neuronu \textit{i}
oraz wejściem następnego neuronu \textit{j}. Każde takie połączenie ma przypisaną
wartość wagi \textit{w\textsubscript{ij}}. Podczas procesu uczenia wagi zmieniają
się, dostosowując sieć neuronową do otrzymywanych danych, co skutkuje
zmniejszeniem wartości błędu.

\paragraph{Bias} \mbox{}\\
Bias to dodatkowa waga wejściowa do neuronu umożliwiająca jego lepsze dopasowanie
do danych treningowych. W sytuacji kiedy wszystkie wagi neuronu mają zerowe
wartości, unikamy problemów podczas procesu wstecznej propagacji.

\paragraph{Warstwa} \mbox{}\\
Sieć neuronowa zorganizowana jest w warstwach. Neurony w danej warstwie nie są
ze sobą w żaden sposób połączone, komunikacja odbywa się tylko między kolejnymi
warstwami. Istnieje wiele rodzajów warstw, a sygnał który przechodzi przez całą
sieć zaczyna się w tzw. warstwie wejściowej oraz kończy w tzw. warstwie wyjściowej.
Istnieją sieci neuronowe (rekurencyjne sieci neuronowe, \textit{(ang. RNN - Recurrent Neural Network)})
w ktorych sygnał może przechodzić przez warstwy kilkukrotnie w trakcie jednej epoki.

\paragraph{Rodzaje warstw} \mbox{}\\
Poniższe rodzaje warstw zostały użyte w modelach przedstawionych w tej pracy.

\subparagraph{Wejściowa}  \mbox{}\\
W pracy, gdzie zbiorami danych są zbiory obrazów, każdy pojedynczy piksel obrazu
odpowiada jednej wartości liczbowej. W związku z tym rozmiar pierwszej warstwy
wejściowej jest identyczny z wymiarami obrazu. Warstwa wejściowa charakteryzuje się
brakiem wejść oraz biasu.

\subparagraph{Wyjściowa}  \mbox{}\\
Rozmiar warstwy wyjściowej odpowiada ilości klas do jakiej wejściowe dane miały
zostać sklasyfikowne. Oczekiwanym wyjściem sieci w pracy była liczba oczek możliwych
do wyrzucenia na kostce, co odpowiada 6 klasom, po jednej na każdą wartość na boku
kostki. Wyjściem wszystkkich przedstawianych w tej pracy sieci był wektor o wymiarach
6x1.

\subparagraph{Konwolucyjna}  \mbox{}\\
Warstwa konwolucyjna służy do przetworzenia danych z poprzedniej warstwy do postaci
filtrów konwolucyjnych o określonych wymiarach w celu znalezienia cech wśród dostarczonych
danych. Więcej informacji na temat sposobu w jaki działa konwolucja, opisane jest w sekcji
\textit{Konwolucja} oraz \textit{Konwolucyjna sieć neuronowa}.

\subparagraph{Aktywacyjna}  \mbox{}\\
Jest to wydzielenie funkcji aktywacji do osobnej warstwy, które jest realizowane
w niektórych bibliotekach. Celem takiego zabiegu jest możliwości podglądu danych
na wyjściu neuronu, tuż przed zaaplikowaniem funkcji aktywacji.

\subparagraph{W pełni połączona}  \mbox{}\\
Sieć neuronowa składa się z w pełni połączonych warstw \textit{(ang. Fully Connected, Dense)}.
W konwolucyjnych sieciach neuronowych warstwy te występują po warstwach konwolucyjnych
i służą do powiązania nieliniowych kombinacji które miały zostały wygenerowane przez
warstwy konwolucyjne oraz ich klasyfikowania. Dodatkowo nie wymagają dużych nakładów
obliczeniowych i są proste do zaaplikowania. Swoją nazwę biorą od sposobu w jaki
realizowane sa połączenia między warstwami. Neurony z poprzedniej warstwy łączą się ze
wszystkimi neuronami następnej warstwy.

\subparagraph{Flatten}  \mbox{}\\
Warstwa spłaszczająca \textit{(ang. Flatten)} stosowana jest w celu połączenia warstw
konwolucyjnych lub aktywacji wraz z warstwami w pełni połączonymi. Realizowane jest
to poprzez przekształcenie warstwy wejściowej do jednowymiarowego wektora który następnie
służy za wejście do kolejnych warstw.

\subparagraph{Odrzucająca}  \mbox{}\\
Warstwa odrzucająca \textit{(ang. Dropout)} zapobiega przetrenowaniu \textit{(ang. Overfitting)}
sieci. Proces ten polega na nie braniu pod uwagę wyjść pewnych neuronów, zarówno
w przypadku przechodzenia w przeód oraz w tył. Stosuje się ją po warstwach w pełni
połączonych, w celu zapobiegania rozległym zależnościom między neuronami. W warstwie
tej określone jest prawdopodobieństwo \textit{p} z jakim neuron zostanie zachowany
w warstwie oraz \textit{p - 1} z jakim zostanie odrzucony.


\subparagraph{MaxPooling}  \mbox{}\\
Warstwa tzw MaxPoolingu wykorzystywana jest do zmniejszenia rozmiaru pamięci oraz
ilości obliczeń wymaganych przez sieć neuronową, jak również może zapobiegać przetrenowaniu.
Operacja zmniejszenia polega na wybraniu jednego piksela z danego obszaru, w przypadku
MaxPoolingu, takiego o największej wartości i przekazaniu go dalej. Obszar z jakiego
wybieramy dany piksel jest zależy od danej warstwy, ale najczęściej jest to kwadrat
o wymiarach 2x2 co oznacza znaczące ograniczenie zużycia pamięci i koniecznych obliczeń.
MaxPooling jest krytykowany ponieważ nie zachowuje informacji o połozeniu piksela
przekazanego na wyjście warstwy co może objawiać się błednymi interpretacjami
podczas testowania sieci.



\paragraph{Funkcja aktywacji} \mbox{}\\
Przy pomocy funkcji aktywacji obliczana jest wartość wyjściowa neuronów w sieci
neuronowej. Argumentem dostarczanym do funkcji aktywacji jest suma wejść neuronu
pomnożonych przez przypisane im wartości wag. Zależnie od konkretnego rodzaju funkcji
aktywacji, neuron po przekroczeniu danego progu wysyła sygnał wyjściowy, odbierany
przez neurony znajdujące się w następnej warstwie.
\begin{equation}
f\Big(\sum_{i}w_{i}x_{i} + b\Big) \\
\end{equation}

\paragraph{Rodzaje funkcji aktywacji} \mbox{}\\
Przedstawione poniżej funkcje aktywacji zostały użyte w modelach zaprezentowanych
w tej pracy.

\subparagraph{Liniowa} \mbox{}\\
Funkcja ta jest praktycznie nie wykorzystywana w sieciach neuronowych. Połączenie
wielu warstw których neurony posiadają liniową funkcję aktywacji można przedstawić
za pomocą jednej warstwy,  ponieważ złożenie wielu funkcji liniowych również będzie
funkcją liniową. Nieliniowość funkcji pozwala na klasyfikacje danych przechodzących
przez sieć.
\begin{equation}
f(x) = x
\end{equation}


\subparagraph{Sigmoid} \mbox{}\\
Największym problemem funkcji sigmoidalnej jest duże ryzyko zaniknięcia gradientu,
co może prowadzić do problemu tzw umierającego neuronu. Zjawisko to ma miejsce
gdy dla danej funkcji aktywacji, gradient staję się bardzo mały. Jest równoznaczne
z zaprzestaniem procesu uczenia, ponieważ gradient zera również wynosi zero.
W przypadku tej funkcji gradient może zanikać obustronnie.
\begin{equation}
f(x) = \sigma(x) = \frac{1}{1 + e^{-x}} \\
\end{equation}

\subparagraph{Tanh} \mbox{}\\
\begin{equation}
f(x) = tanh(x) = \frac{(e^x - e^{-x})}{(e^x + e^{-x})} \\
\end{equation}

\subparagraph{ReLU} \mbox{}\\
ReLU \textit{(and. Rectified linear unit)} jest najpopularniejszą funkcją aktywacji
wykorzystywaną w sieciach neuronowych. Zasługą tego jest szybki czas uczenia sieci
bez znaczącego kosztu w postaci generalizacji dokładności. Problem z zanikającym
gradientem jest mniejszy niż w przypadku funkcji sigmoidalnej, ponieważ występuje
on tylko z jednej strony.
\begin{equation}
f(x) = max(0, x) =
\begin{cases}
 x & \text{if } x \geqslant 0 \\
 0 & \text{if } x < 0 \\
\end{cases}
\end{equation}

\subparagraph{LeakyReLU} \mbox{}\\
LeakyReLU jest ulepszeniem ReLU dzięki zastosowaniu niewielkiego gradientu w sytuacji
dla której ReLU jest nieaktywne. Zmiana ta pozwala na uniknięcie problemu tzw
umierającego neuronu.
\begin{equation}
f(x) =
\begin{cases}
 x & \text{if } x \geqslant 0 \\
 0.01x & \text{if } x < 0 \\
\end{cases}
\end{equation}

\paragraph{Funkcja kosztu} \mbox{}\\
Funkcja kosztu lub funkcja błędu jest niezbędna do prawidłowego przeprowadzenia
procesu uczenia. Daje ona informacje o różnicy między obecnym staniem sieci o
optymalnym rozwiązaniem. Algorytm uczenia sieci analizuje wartość funkcji kosztu
w kolejnych krokach w celu zminimalizowania jej.

\paragraph{Propagacja wsteczna} \mbox{}\\
Propagacja wsteczna lub wsteczna propagacja błędów \textit{(ang. Backpropagation)}
jest jednym z najskuteczniejszych algorytmów uczenia sieci neuronowych. Polega
na minimalizacji funkcji kosztu korzystając z metody najszybszego spadku lub
bardziej zoptymalizowanych sposobów, o których napisane jest w sekcji \textit{Optymalizator}.
Swoją nazwę zawdzięcza sposobowi w jaki propagowane są te błędy, od warstwy
wyjściowej do wejściowej.

\paragraph{Optymalizator} \mbox{}\\
Inne określenie algorytmu optymalizacyjnego wykorzystywanego do obliczania wag neuronów
i biasu sieci neuronowej. Posiada kluczowe znaczenie podczas procesu uczenia sieci
zarówno w kwestii czasu oraz skuteczności. Z tego powodu jest to jeden z kluczowych
obszarów obecnych badań i rozwoju sieci neuronowych.

\subparagraph{Metoda gradientu prostego} \mbox{}\\
Metoda gradientu prostego \textit{(ang. Gradient Descent)} jest podstawowym algorytmem
służacym do uaktualniania wartości wag oraz biasu podczas uczenia sieci. Wadą tej
metody jest przeprowadzanie jednorazowej aktualizacji po wyliczeniu gradientu dla
całego zestawu danych. Jest to bardzo wolne, w niektórych przypadkach może powodować
problem z ilością zajmowanego miejsca w pamięci a przede wszystkim może prowadzić
do pozostania w jednym z lokalnych minimów funkcji.
\begin{equation}
\theta = \theta - \eta * \nabla J(\theta)
\end{equation}

\subparagraph{Stochastic Gradient Descent} \mbox{}\\
\textit{(nazwa w języku angielskim z powodu braku znalezienia polskiego odpowiednika)}
Stochastic Gradient Descent \textit{(skrót. GDA)} jest rozwinięciem metody gradientu
prostego, bardzo często wykorzystywana w praktyce. Ulepszenie polega na obliczaniu
gradientu dla jednego lub niewielkiej ilości przykładów treningowych. Najczęsciej
korzysta się z więcej niż jednego przykładu co zapewnia lepszą stabilność oraz
wykorzystuje zrównoleglanie obliczeń. SGD zapewnia to większą rozbieżność niż metoda
gradiento prostego, co umożliwia znajdowanie nowych lokalnych minimów ale wiąże się
z koniecznością zastosowania mniejszego stopnia uczenia.
\begin{equation}
\theta = \theta - \eta * \nabla J(\theta; x_i; y_i)
\end{equation}

\subparagraph{RMSprop} \mbox{}\\
RMSprop umożliwia obliczanie gradientu dla każdego parametru z osobna i zapobiega
zmniejszaniu się stopnia uczenia. Algorytm dostosowuje stopień uczenia dla każdej wagi
bazując na wielkości jej gradientu.

\subparagraph{Adam} \mbox{}\\
Adam to skrót od angielskiej nazwy \textit{Adaptive Moment Estimation} i jest rozwinięciem
metody Stochastic Gradient Descent. Metoda ta pozwala na obliczanie z osobna gradientu dla
każdego parametru oraz każdej zmiany momentum. Zapobiega dodatkowo zmniejszającemu się
stopniowi uczenia, a co najważniejsze jest bardzo szybka i pozwala na sprawne uczenie
się sieci. W tej metodzie obliczamy dwa momenty \textit{m} oraz \textit{v}.
\begin{equation}
\begin{align*}
\hat{m_t} = \frac{m_t} {1 - \beta^t_1}, \\
\hat{v_t} = \frac{v_t} {1 - \beta^t_2}, \\
\end{align*}
\end{equation}
Powyżej obliczone momenty podstawiamy do wzoru
\begin{equation}
\theta_{t+1} = \theta_t - \frac {\eta} {\sqrt{\hat{v_t}} + \epsilon} \hat{m_t}
\end{equation}
gdzie najczęściej \textbeta \textsuperscript{t}\textsubscript{1} = 0.9 oraz
\textbeta \textsuperscript{t}\textsubscript{2} = 0.99 a \straightepsilon = 10^{-8}\\

\paragraph{Sieć neuronowa} \mbox{}\\

\paragraph{Konwolucja} \mbox{}\\

\paragraph{Filtr konwolucyjny} \mbox{}\\

\paragraph{Konwolucyjna sieć neuronowa} \mbox{}\\

\paragraph{Paradygmaty uczenia} \mbox{}\\

\paragraph{Epoka} \mbox{}\\
Proces uczenia sieci podzielony jest na epoki. Każda epoka odpowiada przejściu
wszystkich elementów z treningowego zbioru danych przez sieć. Ilość epok podczas
których sieć będzie sie uczyć ustala się na co najmniej kilkanaście. W przypadku
większych zbiorów danych lub większych modeli sieci zwiększamy ilość epok. \\
Często spotykaną praktyką w wielu pracach naukowych jest przedstawianie wyników
dla sieci po 100 epokach uczenia się.

\paragraph{Uczenie} \mbox{}\\
Proces uczenia bądź treningu sieci służy zmianie wartości wag, najczęściej zainicjowanych
pseudolosowymi wartościami oraz biasu. Uczenie się sieci neuronowej jest bardzo
kosztowne obliczeniowo, co wręcz uniemożliwiało trenowanie modeli w przeszłości,
a obecnie jest jednym z powodów dużego technologicznego przeskoku w produkcji kart
graficznych. Operacje dodawania i mnożenia wektór i macierzy wykonywane są setki
milionów razy, które mogą być przyśpieszone dzięki możliwościom zrównoleglania obliczeń. \\

\paragraph{Testowanie} \mbox{}\\
Model sieci neuronowej może zostać poddany ocenie, dzięki której można określić w jakim stopniu
nauczyła się sieci. W przypadku wytrenowanych modeli istotne jest aby zbiór służący do
testowania nie był wcześniej użyty do treningu sieci. Nauczony model powinien być w stanie
rozpoznawać nowe, nieużyte podczas procesu uczenia dane i poprawnie je klasyfikować.

\paragraph{Predykcja} \mbox{}\\
Wartości zwrócone przez sieć po umieszczeniu w niej określonych danych są określane
mianem predykcji. Pozwala to na wykorzystanie nauczonego modelu w praktycznym
zastosowaniu. \\ \\ \\

Tematy do uwzględnienia:
minibatch,
nesterov,
momentum,
softmax,
learning rate,
categorical crossentropy,
Liczebność zbioru (konkretne uzasadnienie konieczności duzej liczby danych),
one-hot encoding,
hyperparameters: ilosc filtrow, rozmiar filtrow, rozmiar maxpoolingu
