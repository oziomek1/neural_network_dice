% !TEX encoding = UTF-8 Unicode

\chapter{Słownik pojęć}
\section{Zbiór danych}
Do realizacji pracy konieczny było stworzenie zbioru danych składającego się z obrazów
z kośćmi do gry. Zdjęcia zostały zrobione kamerą o rozdzielczości 1600x1200 pikseli,
a następnie zmniejszone w celu zaoszczędzenia pamięci i osiągnięcia żądanego rozmiaru,
który ma kluczowe znaczenie w przypadku zastosowań sieci neuronowych.
Oprócz zmniejszenia obrazy były również obracane, deformowane \textit{(warping)} oraz kadrowane.
Tak powstałe, liczne zbiory były wykorzystywane w trybie RGB oraz w odcieniach skali szarości,
co pozwoliło na oszczędzenie pamięci przez zmniejszenie liczby kanałów do jednego.\\
W pracy używano zbiorów z obrazami o rozmiarach 64x64 oraz 106x79 pikseli. Każde zdjęcie
w zbiorze miało przypisaną wartość liczbową informującą o faktycznej ilości oczek wyrzuconych
na przedstawionej kostce. Wartość ta zwana jest odpowiedzią i jest wykorzystywana w
procesie uczenia sieci jako docelowa informacja, którą ma zwrócić sieć po weryfikacji danego obrazu.

\paragraph{Zbiór treningowy} \mbox{}\\
Część zbioru danych, która wykorzystywana jest w procesie uczenia sieci, określana jest jako zbiór
treningowy lub zbiór uczący. Jego liczebność to zazwyczaj 60-80\% całego zbioru danych.
Zawsze przed rozpoczęciem uczenia, dane znajdujące się w tym zbiorze poddawane są losowej permutacji.

\paragraph{Zbiór testowy} \mbox{}\\
Do oceny zdolności sieci neuronowej do rozpoznawania danych służy zbiór testowy lub
walidacyjny. Zbiór jest oddzielony od treningowego, by podczas weryfikacji sieci operowano
na nieznanych jej wcześniej danych.

\section{Budowa sieci neuronowej}
\paragraph{Sieć neuronowa} \mbox{}\\
Sieć neuronowa \textit{(ang. ANN Artificial Neural Network)} to struktura matematyczna,
składająca się z neuronów połączonych w warstwy, mająca odzwierciedlać działanie
biologicznych sieci neuronowych, a w szczególności mózgu \cite{intuitiveExplanation, WIKIcnn}.
Sieci mają szerokie zastosowanie w bardzo wielu dziedzinach. Wymagają jednak kosztownego obliczeniowo i czasowo
procesu uczenia, podczas którego dostosowują się do danego problemu. Użycie wytrenowanej
sieci, nie wymaga powtarzania uczenia, co pozwala na jej natychmiastowe wykorzystanie.
Przykładowa ilustracja sieci neuronowej przedstawiona jest poniżej \ref{fig:cnn_layers}.
\begin{figure}[h!]
\centering
\includegraphics[scale=0.35]{cnn_layers}
\\
\centering
https://www.mathworks.com/solutions/deep-learning/convolutional-neural-network.html}
\caption{Przykładowa sieć neuronowa.}
\label{fig:cnn_layers}
\end{figure}

\paragraph{Neuron} \mbox{}\\
Neuron jest najmniejszym elementem sieci neuronowej, posiadającym wiele wejść i jedno wyjście \cite{CS231n_activ, NNbiology, NeuronAnimation}.
Sygnały z neuronów w poprzednich warstwach docierają na każde z wejść neuronu z przypisaną mu wagą. 
W neuronie obliczana jest suma ważona wejść, która porównywana jest zwartością progową,
inaczej biasem \cite{needForBias}. Jeśli przekroczy ona wartość progową to neuron jest uaktywniany,
a suma przekazywana jest do funkcji aktywacji. Wartość funkcji przekazywana jest na wyjście neuronu.\\
Poniższy wzór \ref{eq:neuron} przedstawia sumę ważoną wejść neuronu wraz z dodatkową wagą.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:neuron}
f(x_{i}) = f\Big(\sum_{i}w_{i}x_{i} + b \Big)\\
\end{equation}\centering
gdzie: \textit{w} - wagi wejść neuronu, \textit{x} - wartość sygnału na wejściu, \textit{b} - bias
\caption{Suma ważona w neuronie wraz z dodatkową wagą \textit{b}}
\end{figure}

\paragraph{Wagi neuronu} \mbox{}\\
Jak opisano już wcześniej, neurony połączone są między sobą dzięki licznym wejściom.
Każde takie połączenie ma przypisaną wagę, która zmienia się podczas treningu,
dostosowując sieć neuronową do danych treningowych. Efektem tego jest osiąganie
coraz lepszych wyników w miarę trwania procesu uczenia.

\paragraph{Warstwa} \mbox{}\\
Neurony w sieci zorganizowane są w warstwach. Komunikacja odbywa się tylko między kolejnymi
warstwami, neurony w danej warstwie nie są ze sobą połączone \cite{CS231n, substBigConv}.
Istnieje wiele rodzajów warstw, a sygnał przechodzący przez całą sieć zaczyna się w tzw.
warstwie wejściowej oraz kończy w tzw. warstwie wyjściowej.

\paragraph{Funkcja kosztu} \mbox{}\\
Do uzyskiwania informacji o wartości błędu pomiędzy wartościami przewidzianymi przez sieć
a wartościami docelowymi wykorzystywana jest funkcja kosztu lub funkcja błędu.
Jest ona niezbędna do prawidłowego przeprowadzenie procesu uczenia.
Funkcja dostarcza informacje o różnicy między obecnym stanem sieci a optymalnym
rozwiązaniem dla danych treningowych. Algorytm uczenia
oblicza wartość funkcji kosztu w kolejnych krokach w celu jej zminimalizowania.\\
Najczęściej wykorzystywaną funkcją kosztu jest błąd średniokwadratowy \ref{eq:mse}.
W tej pracy z uwagi na posiadanie 6 możliwych do uzyskania wyników na wyjściu sieci
zastosowano wielowymiarową entropię krzyżową (\textit{ang. Categorical cross-entropy}) \ref{eq:categorical-crossentropy},
która jest preferowana, ponieważ zapobiega uwypukleniu nieprawidłowych wartości \cite{whyNotMSE}. Jest również
sugerowana przez bibliotekę Keras oraz wykorzystywana w wielu przykładowych modelach sieci neuronowych.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:mse}
J(\eta) = \frac {1}{2} \sum_{i}^{m} \Big(h_{\theta}(x^{(i)}) - y^{(i)} \Big)^2\\
\end{equation}
\centering
gdzie: \textit{h\textsubscript{\straighttheta}(x)} - wartość przewidziana przez sieć, \textit{y} - wartość oczekiwana
\caption{Błąd średniokwadratowy}
\end{figure}
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:categorical-crossentropy}
L_{i} = - \sum_{j} t_{i,j} log(p_{i,j})\\
\end{equation}
\centering
gdzie: \textit{p} - predykcje, \textit{t} - cele, \textit{i} - wartość, \textit{j} - klasa
\caption{Wielowymiarowa entropia krzyżowa}
\end{figure}

\section{Propagacja wsteczna}
Propagacja wsteczna lub wsteczna propagacja błędów \textit{(ang. Backpropagation)}
jest algorytmem uczenia sieci neuronowych \cite{CS231n_backprop, backprop}.
Służy do wyliczenia gradientu funkcji kosztu, który informuje o szybkości spadku wartości tej funkcji
z uwzględnieniem wag neuronów. Obliczenie gradientu w sieci propagowane
jest od warstwy wyjściowej do wejściowe, czemu algorytm zawdzięcza swoją nazwę.

\section{Konwolucyjna sieć neuronowa}

Przy wykorzystywaniu sieci neuronowych do operowania na zdjęciach, pojawia się problem
z dużą ilością parametrów odpowiadających wartościom każdego z pikseli.
W celu ich zmniejszenia stosuje się konwolucyjne sieci neuronowe \textit{(ang. CNN - Convolutuinal Neural Network)}.
Zamiast przekazywać informacje o wszystkich pikselach znajdujących się
na obrazach, sieć analizuje je przy użyciu filtrów konwolucyjnych.
Te wartości przesyłane są dalej do następnej warstwy.\\
Obecnie ten typ sieci odnosi największe osiągnięcia w dziedzinie rozpoznawania obrazów,
w wielu przypadkach dorównując lub nawet pokonująć ludzkie wyniki.

\paragraph{Konwolucja} \mbox{}\\
Wymieniona wyżej konwolucja, inaczej splot, polega na złożeniu dwóch funkcji. W przypadku obrazów
jedna z tych funkcji to obraz, który ma rozmiary większe niż druga funkcja określana
mianem filtra konwolucyjnego. Zastosowanie splotu, w zależności od przypadku,
pozwala na rozmycie, wyostrzanie lub wydobycie głębi z danego obrazu \cite{konwolucja}.
Poniższy wzór \ref{eq:conv} przedstawia sposób obliczenia splotu dwóch funkcji.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:conv}
h[m, n] = (f * g)[m, n] = \sum_j^m \sum_k^n f[j, k] * g[m-j, n-k] \\
\end{equation}
\centering
\captionsetup{justification=centering,margin=1cm}
\caption{Splot funkcji. Funkcja \textit{f} to dwuwymiarowa macierz z pikselami obrazu. Funkcja \textit{g} to filtr. Funkcja \textit{h} to nowo otrzymany obraz.}
\end{figure}

\section{Warstwy sieci neuronowej}

W sieciach neuronowych wyróżniamy kilka rodzajów warstw, które poza wejściową i wyjściową,
można dobierać zależnie od sposobu rozwiązania danego problemu i typu posiadanych danych.

\paragraph{Wejściowa} \mbox{}\\
W sytuacji, gdy danymi jest zbiór obrazów, warstwa wejściowa ma rozmiar identyczny z
wymiarami obrazu.

\paragraph{Wyjściowa} \mbox{}\\
Rozmiar warstwy wyjściowej odpowiada ilości klas, do jakiej dane były rozdzielane.
W tej pracy, gdzie oczekiwanym wyjściem była liczba oczek możliwych do wyrzucenia na
kostce, odpowiada on 6 klasom. Wyjściem takiej sieci jest więc wektor o wymiarach 6x1.

\paragraph{Konwolucyjna} \mbox{}\\
Warstwa konwolucyjna służy do przetworzenia danych z poprzedniej warstwy przy użyciu
filtrów konwolucyjnych \cite{CS231n}. Filtry mają określone wymiary i służą do znajdowania cech
na obrazach lub ich fragmentach. Zastosowanie wielu warstw konwolucyjnych umożliwia filtrom
analizowanie bardziej złożonych zależności na obrazach.

\paragraph{W pełni połączona} \mbox{}\\
Najpopularniejszy typ warstwy to w pełni połączony \textit{(ang. Fully Connected, Dense)}.
Każdy neuron łączy się ze wszystkimi neuronami następnej warstwy, co skutkuje dużą ilością
potrzebnych do wykonania obliczeń.
W sieciach konwolucyjnych umieszczane są zwykle po warstwach konwolucyjnych
i służą do powiązania nieliniowych kombinacji i ich sklasyfikowania.

\paragraph{Flatten} \mbox{}\\
Warstwa spłaszczająca \textit{(ang. Flatten)} stosowana jest w celu połączenia warstw
konwolucyjnych z warstwami w pełni połączonymi. Realizowane jest to poprzez przekształcenie
warstwy wejściowej do jednowymiarowego wektora, który następnie służy za wejście
do kolejnych warstw.

\paragraph{Odrzucająca} \mbox{}\\
Użycie warstwy odrzucającej \textit{(ang. Dropout)} jest jednym z najlepszych sposobów
na poradzenie sobie ze zjawiskiem przetrenowania, opisanym na końcu tego rozdziału
\cite{DropoutPreventOverfit}. Warstwa odrzucająca nie wykorzystuje wyjść pewnych neuronów,
co zapobiega rozległym zależnościom między neuronami. W warstwie tej określamy prawdopodobieństwo,
z jakim neurony zostaną zachowane. Najczęściej stosuje się ją po warstwach w pełni
połączonych, zarówno przy przechodzeniu w przód, jak i tył \cite{DropConnect}.

\paragraph{Pooling} \mbox{}\\
Warstwa ta wykorzystywana jest do zmniejszenia rozmiaru pamięci oraz ilości obliczeń
w sieci neuronowej. Operacja polega na wybraniu jednego piksela z danego obszaru i przekazaniu
go do następnej warstwy. Najczęściej wykorzystywaną warstwą poolingową jest MaxPooling, wybierający
piksel o największej wartości. Pooling jest krytykowany za brak zachowywania informacji
o położeniu piksela przekazanego na wyjście warstwy, co może objawiać się błędnymi
interpretacjami danych przez sieci.

\section{Funkcje aktywacji}

Pomnożona suma wartości wejściowych i ich wag zostaje przekazana
jako argument do funkcji aktywacji, a obliczona wartości staje się wyjściem neuronu.
Wybór funkcji jest jednym z kluczowych parametrów danej sieci, ponieważ niewłaściwy wybór
może prowadzić do problemów podczas uczenia sieci.

\paragraph{Sigmoid} \mbox{}\\
Sigmoid jest popularną funkcją aktywacji. Problemem z nią związanym
jest ryzyko zaniknięcia gradientu, co może prowadzić do problemu tzw. umierającego
neuronu \cite{activationFunctions}. Występuje ono, gdy dla danej funkcji aktywacji,
gradient staje się bardzo mały, co jest równoznaczne z zaprzestaniem procesu uczenia.
W sigmoid gradient może zanikać obustronnie. Wzór funkcji sigmoidalnej pokazany jest poniżej \ref{eq:sigmoid}.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:sigmoid}
f(x) = \sigma(x) = \frac{1}{1 + e^{-x}} \\
\end{equation}
\caption{Funkcja sigmoidalna}
\end{figure}

\paragraph{Tangens hiperboliczny} \mbox{}\\
Tangens hiperboliczny lub tanh jest w istocie przekształconą funkcją sigmoidalną
\cite{activationFunctions, activationFunctionsV2}. Wykorzystanie
jej powoduje większe wahania gradientu. Wzór na obliczenie tangensu hiperbolicznego
zaprezentowany jest poniżej \ref{eq:tanh}.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:tanh}
f(x) = tanh(x) = \frac{(e^x - e^{-x})}{(e^x + e^{-x})} = \frac{2}{1+e^{-2x}} - 1 = 2 sigmoid(2x) - 1\\
\end{equation}
\caption{Tangens hiperboliczny}
\end{figure}

\paragraph{ReLU} \mbox{}\\
ReLU \textit{(and. Rectified linear unit)} jest najpopularniejszą funkcją
aktywacji wykorzystywaną w sieciach neuronowych \cite{CS231n_activ, WIKIrectifier}.
Zasługą tego jest szybki czas uczenia sieci bez znaczącego kosztu w postaci generalizacji
dokładności. Problem z zanikającym gradientem jest mniejszy niż w przypadku funkcji
sigmoidalnej, ponieważ występuje on tylko z jednej strony.
Wzór \ref{eq:relu} na obliczenie ReLU przedstawiony jest poniżej.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:relu}
f(x) = max(0, x)
\end{equation}
\caption{ReLU - Rectified linear unit}
\end{figure}

\paragraph{LeakyReLU} \mbox{}\\
LeakyReLU jest ulepszeniem funkcji ReLU \cite{CS231n_activ} dzięki zastosowaniu niewielkiego
gradientu w sytuacji, dla której ReLU jest nieaktywne. Zmiana ta pozwala na uniknięcie
problemu znikającego gradientu. Jej wzór \ref{eq:leakyrelu} przedstawiony jest poniżej.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:leakyrelu}
f(x) =
\begin{cases}
x & \text{if } x \geqslant 0 \\
0.01x & \text{if } x < 0 \\
\end{cases}
\end{equation}
\caption{LeakyReLU}
\end{figure}

\paragraph{Softmax} \mbox{}\\
Softmax jest funkcją obliczającą rozkład prawdopodobieństwa wystąpienia danego zdarzenia
ze wszystkich możliwych. Wykorzystywana jest w zadagnieniach wymagających przyporządkowania
elementu do jednej z wielu klas. Wzór funkcji \ref{eq:softmax} zaprezentowany jest poniżej.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:softmax}
f(x_{i}) = \frac{e^{x_{i}}} {\sum_{j = 0}^{k}(e^{x_{j}})}
\end{equation}
\caption{Funkcja softmax}
\end{figure}

\section{Optymalizator}

Algorytmy optymalizacyjne wykorzystywane są do minimalizacji funkcji błędu poprzez
znajdowanie nowych wartości wag neuronów w sieci neuronowej. Ma kluczowe
znaczenie podczas procesu uczenia sieci w kwestii czasu oraz skuteczności.
Z tego powodu to zagadnienie jest obiektem wielu obecnych badań i rozwoju sieci
neuronowych \cite{typesOfOptimizationAlgorithms}.

\paragraph{Współczynnik uczenia} \mbox{}\\
Do ustalenia z jakąś szybkością sieć neuronowa będzie dostosowywać się do danych, wykorzystujemy
współczynnik lub wskaźnik uczenia \textit{(ang. lerning rate)}. Wybranie zbyt małego
współczynnika wydłuży proces uczenia, a zbyt duża jego wartość może spowodować problemy
ze znalezieniem optymalnego rozwiązania. W niektórych algorytmach współczynnik uczenia
zmniejsza się w czasie, by lepiej dostosować się do danych i zniwelować oba wspomniane problemy.

\paragraph{Metoda największego spadku} \mbox{}\\
Metoda największego spadku \textit{(ang. Gradient Descent)} jest podstawowym algorytmem
służącym do zmiany wartości wag podczas procesu uczenia sieci.
Wadą tej metody jest przeprowadzanie jednorazowej aktualizacji po wyliczeniu gradientu dla
całego zestawu danych. Spowalnia to uczenie i może powodować problem z ilością zajmowanego
miejsca w pamięci. Sporą wadą jest możliwość doprowadzenia do stagnacji w jednym z
lokalnych minimów funkcji. Wzór \ref{eq:gradientdescent} znajduje się poniżej.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:gradientdescent}
\theta = \theta - \eta * \nabla J(\theta)
\end{equation}
\centering
gdzie: \texteta - współczynnik uczenia, \textit{J} - funkcja błedu
\caption{Metoda największego spadku}
\end{figure}

\paragraph{Stochastic gradient descent} \mbox{}\\
Stochastic gradient descent \textit{(skrót. SGD)} jest rozwinięciem metody gradientu
prostego, bardzo często wykorzystywana w praktyce \cite{OptimizersOverview}.
Ulepszenie polega na obliczaniu gradientu dla jednego lub niewielkiej ilości przykładów
treningowych. Najczęściej korzysta się z więcej niż jednego przykładu, co zapewnia
lepszą stabilność oraz wykorzystuje zrównoleglenie obliczeń. SGD pozwala na lepsze dopasowanie
niż metoda gradientu prostego, ale wiąże się z koniecznością zastosowania mniejszego
współczynnika uczenia. Sposób obliczania SGD \ref{eq:sgd} przedstawiony jest poniżej.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:sgd}
\theta = \theta - \eta * \nabla J(\theta; x_i; y_i)
\end{equation}
\centering
gdzie \texteta - współczynnik uczenia, \textit{J} - funkcja błedu,
\textit{x, y} - wejściowe i wyjściowe dane treningowe dla określonej iteracji
\caption{Stochastic gradient descent}
\end{figure}

\paragraph{Adam} \mbox{}\\
Adam to skrót od angielskiej nazwy \textit{Adaptive Moment Estimation} i jest rozwinięciem
metody Stochastic Gradient Descent \cite{AdamOptimizer, OptimizersOverview}.
Metoda ta zapewnia dostosowanie współczynnika uczenia z osobna do każdego z parametrów,
korzystając przy tym z pierwszego i drugiego momentu centralnego, czyli odpowiednio ze
średniej oraz wariancji. Adam obecnie jest bardzo popularny z uwagi na szybkość działania
i osiąganie bardzo dobrych wyników. Poniższe wzory przedstawiają sposób na jego obliczenie \ref{eq:moments_adam} \ref{eq:adam}.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:moments_adam}
\begin{align*}
\hat{m_t} = \frac{m_t} {1 - \beta^t_1}, \\
\hat{v_t} = \frac{v_t} {1 - \beta^t_2}, \\
\end{align*}
\end{equation}
\caption{Wzór na obliczanie pierwszego \textit{(m)} i drugiego \testit{(v)} momentu centralnego}
\end{figure}
Obliczone momenty podstawiane są do wzoru
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation} \label{eq:adam}
\theta_{t+1} = \theta_t - \frac {\eta} {\sqrt{\hat{v_t}} + \epsilon} \hat{m_t}
\end{equation}
\centering
gdzie najczęściej \textbeta \textsuperscript{t}\textsubscript{1} = 0.9 oraz
\textbeta \textsuperscript{t}\textsubscript{2} = 0.99 a \straightepsilon = 10^{-8}\\
\caption{Optymalizator Adam}
\end{figure}

\section{Przetrenowanie}
Zjawisko przetrenowania \textit{(ang. Overfitting)} polega na błędnym rozpoznawaniu nowych danych,
kiedy podczas treningu sieć uczyła się poprawnie. Może być ono bardzo trudne do wykrycia,
co powoduje, że jest jednym z największych problemów podczas pracy z sieciami neuronowymi.
Istnieje wiele sposobów na ograniczenie przetrenowania, a jedną z najlepszych technik
jest zastosowanie warstw odrzucających \cite{DropoutPreventOverfit}.

\section{Procesy}

Pracy z sieciami neuronowymi towarzyszy kilka procesów, które są niezbędne do tworzenia
oraz korzystania z nich.

\paragraph{Uczenie} \mbox{}\\
Uczenie bądź trening sieci jest procesem, w którym wagi sieci dostosowują się do dostarczonych danych.
Nauczona sieć powinna sprawnie realizować zamierzone zadanie, na przykład poprawnego
rozpoznawania ilości oczek wyrzuconych na kostce. Trening jest bardzo kosztowny obliczeniowo,
ponieważ operacje dodawania i mnożenia wektorów oraz macierzy wykonywane są miliony razy.

\paragraph{Epoka} \mbox{}\\
Podczas uczenia się, przez sieć przechodzą wszystkie elementy z treningowego zbioru danych.
Jednorazowe przejście wszystkich tych elementów nazywane jest epoką. W praktycznym zastosowaniu
ilość epok ustala się na co najmniej kilkanaście, chociaż w wielu pracach naukowych przedstawiane
są wyniki po 100 epokach treningu.

\paragraph{Testowanie} \mbox{}\\
Testowanie polega na porównaniu wyników dla zbioru testowego z oczekiwanymi wartościami.
Istotne jest, aby zbiór służący do testowania nie był wcześniej użyty do treningu sieci.
Nauczony model powinien być w stanie rozpoznawać nowe, nieużyte podczas procesu uczenia
dane i poprawnie je klasyfikować.

\paragraph{Predykcja} \mbox{}\\
Wartości zwrócone przez sieć po umieszczeniu w niej określonych danych nazywane są
predykcją. Pozwala to na wykorzystanie nauczonego modelu w praktycznym zastosowaniu.

\section{Inne}

\paragraph{MNIST} \mbox{}\\
Baza danych MNIST \cite{MNIST} to zbiór 60000 treningowych i 10000 testowych czarno-białych obrazów
w rozmiarze 28x28x1, zawierających ręcznie napisane cyfry 0-9. Jest jednym z
najpopularniejszych zbiorów służących do rozpoczęcia nauki sztucznych sieci neuronowych
i uczenia maszynowego.

\paragraph{CIFAR-10} \mbox{}\\
Zbiór CIFAR-10 \cite{CIFAR-10} składa się z 50000 treningowych i 10000 testowych kolorowych obrazów w rozmiarze
32x32x2. Jest podzielony na 10 klas: samolot, samochód, ptak, kot, jeleń, pies, żaba,
koń, statek, ciężarówka; gdzie każdej z nich przypada po 6000 obrazów. Jest to podobnie
jak MNIST jeden z najbardziej popularnych zbiorów do uczenia maszynowego i sieci neuronowych.
