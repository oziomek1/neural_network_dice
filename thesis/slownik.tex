% !TEX encoding = UTF-8 Unicode

\chapter{Słownik pojęć}
Z sieciami neuronowymi wiąże się wiele pojęć, na które napotyka się podczas pracy z nimi.
Poniżej znajduje się opis kluczowych elementów architektury sieci i zagadnień niezbędnych
do realizacji tej pracy.

\section{Zbiór danych}
Do realizacji pracy konieczne było stworzenie zbioru danych składającego się z obrazów
z kośćmi do gry. Zdjęcia zostały zrobione kamerą o rozdzielczości 1600x1200 pikseli,
a następnie zmniejszone w celu zaoszczędzenia pamięci i ilości danych,
która ma kluczowe znaczenie w przypadku zastosowań sieci neuronowych.
Oprócz zmniejszenia obrazy były również obracane, deformowane \textit{(ang. warping)} oraz kadrowane.
Tak powstałe, liczne zbiory były wykorzystywane w trybie RGB oraz w odcieniach skali szarości,
co pozwoliło na przyśpieszenie pracy przez zmniejszenie liczby kanałów do jednego.\\
W pracy używano zbiorów z obrazami o rozmiarach 64x64 oraz 106x79 pikseli. Każde zdjęcie
w zbiorze miało przypisaną wartość liczbową informującą o faktycznej ilości oczek wyrzuconych
na przedstawionej kostce. Wartość ta zwana jest odpowiedzią i wykorzystywana jest w
procesie uczenia sieci jako docelowa informacja, którą sieć ma zwrócić po weryfikacji danego obrazu.

\paragraph{Zbiór treningowy} \mbox{}\\
Część zbioru danych, która wykorzystywana jest w procesie uczenia sieci, określana jest jako zbiór
treningowy lub zbiór uczący. Jego liczebność to zazwyczaj 60-80\% całego zbioru danych.
W tej pracy zawsze przed rozpoczęciem uczenia, dane znajdujące się w tym zbiorze poddawane są losowej permutacji.

\paragraph{Zbiór testowy} \mbox{}\\
Do oceny zdolności sieci neuronowej do rozpoznawania danych służy zbiór testowy lub
walidacyjny. Zbiór jest oddzielony od treningowego, by podczas weryfikacji sieci operowano
na nieznanych jej wcześniej danych.

\section{Budowa sieci neuronowej}
\paragraph{Sieć neuronowa} \mbox{}\\
Sieć neuronowa \textit{(ang. ANN Artificial Neural Network)} to struktura matematyczna,
składająca się z neuronów połączonych w warstwy, mająca odzwierciedlać działanie
biologicznych sieci neuronowych, a w szczególności mózgu \cite{CS231n_activ}.
Sieci mają szerokie zastosowanie w bardzo wielu dziedzinach. Wymagają jednak kosztownego obliczeniowo i czasowo
procesu uczenia, podczas którego dostosowują się do danego problemu. Użycie wytrenowanej
sieci, nie wymaga powtarzania uczenia, co pozwala na jej natychmiastowe wykorzystanie.
Przykładowa ilustracja sieci neuronowej przedstawiona jest poniżej (zob. rys. \ref{fig:cnn_layers})
\begin{figure}[h!]
\centering
\includegraphics[scale=0.35]{cnn_layers}
\\
\centering
https://www.mathworks.com/solutions/deep-learning/convolutional-neural-network.html}
\caption{Przykładowa sieć neuronowa.}
\label{fig:cnn_layers}
\end{figure}

\paragraph{Neuron} \mbox{}\\
Neuron jest najmniejszym elementem sieci neuronowej, posiadającym wiele wejść i jedno wyjście \cite{NNbiology, NeuronAnimation}.
Sygnały z neuronów w poprzednich warstwach docierają na każde z wejść neuronu z przypisaną mu wagą.
W neuronie obliczana jest suma ważona wejść, od której odejmowana jest z wartość progowa
inaczej bias \cite{needForBias}. Przekroczenie wartości progowej uaktywnia neuron,
a wartość sumy przekazywana jest do funkcji aktywacji. Wartość funkcji przekazywana jest na wyjście neuronu.
Poniższy wzór \ref{eq:neuron} przedstawia sumę ważoną wejść neuronu.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation*}
f(x_{i}) = f\Big(\sum_{i}w_{i}x_{i} - b \Big)\\
\end{equation*}\centering
gdzie: \textit{w} - wagi wejść neuronu, \textit{x} - wartość sygnału na wejściu, \textit{b} - bias
\caption{Suma ważona w neuronie wraz biasem \textit{b}}
\label{eq:neuron}
\end{figure}

\paragraph{Wagi neuronu} \mbox{}\\
Jak napisano wcześniej, każde połączenie między pojedynczymi neuronami ma przypisaną wagę,
która zmienia się podczas treningu, dostosowując sieć neuronową do danych treningowych.
Efektem tego jest osiąganie coraz lepszych wyników w miarę trwania procesu uczenia.

\paragraph{Warstwa} \mbox{}\\
Neurony w sieci zorganizowane są w warstwach. Komunikacja odbywa się tylko między kolejnymi
warstwami, neurony w danej warstwie nie są ze sobą połączone \cite{CS231n, substBigConv}.
Istnieje wiele rodzajów warstw, które opisane będą w dalszej części tego rozdziału.

\paragraph{Funkcja kosztu} \mbox{}\\
Informacje o wartości błędu pomiędzy wartościami przewidzianymi przez sieć
a wartościami docelowymi można uzyskiwać dzięki funkcji kosztu lub funkcji błędu.
Jest ona niezbędna do prawidłowego przeprowadzenie procesu uczenia.
Funkcja dostarcza informacje o różnicy między obecnym stanem sieci a optymalnym
rozwiązaniem dla danych treningowych. Algorytm uczenia
oblicza wartość funkcji kosztu w kolejnych krokach w celu jej zminimalizowania.\\
Najczęściej wykorzystywaną funkcją kosztu jest błąd średniokwadratowy \ref{eq:mse}.
W tej pracy z uwagi na posiadanie 6 możliwych do uzyskania wyników na wyjściu sieci
zastosowano wielowymiarową entropię krzyżową (\textit{ang. Categorical cross-entropy}) \ref{eq:categorical-crossentropy},
która zapobiega uwypukleniu nieprawidłowych wartości \cite{whyNotMSE}. Jest również
sugerowana przez bibliotekę Keras oraz wykorzystywana w wielu przykładowych modelach sieci neuronowych.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation*}
J(\eta) = \frac {1}{2} \sum_{i}^{m} \Big(h_{\theta}(x^{(i)}) - y^{(i)} \Big)^2\\
\end{equation*}
\centering
gdzie: \textit{h\textsubscript{\straighttheta}(x)} - wartość przewidziana przez sieć, \textit{y} - wartość oczekiwana
\caption{Błąd średniokwadratowy}
\label{eq:mse}
\end{figure}
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation*}
L(p, q) = - \sum_{i} p_{i} log(q_{i})\\
\end{equation*}
\centering
gdzie: \textit{p} - rozkład prawdopodobieństwa dla prawdziwych wartości, \textit{q} - rozkład prawdopodobieństwa dla predykcji
\caption{Wielowymiarowa entropia krzyżowa}
\label{eq:categorical-crossentropy}
\end{figure}

\section{Propagacja wsteczna}
Propagacja wsteczna lub wsteczna propagacja błędów \textit{(ang. Backpropagation)}
jest algorytmem uczenia sieci neuronowych \cite{CS231n_backprop, backprop}.
Służy do wyliczenia gradientu funkcji kosztu, który informuje o szybkości spadku wartości tej funkcji
z uwzględnieniem wag neuronów. Obliczenie gradientu w sieci propagowane
jest od warstwy wyjściowej do wejściowej, czemu algorytm zawdzięcza swoją nazwę.

\section{Konwolucyjna sieć neuronowa}

Korzystanie z sieci neuronowych do operowania na zdjęciach sprawia problemy
z dużą ilością parametrów odpowiadających wartościom każdego z pikseli.
Zapobiega temu stosowanie konwolucyjnych sieci neuronowych \textit{(ang. CNN - Convolutuinal Neural Network)} \cite{intuitiveExplanation, WIKIcnn}.
Zamiast przekazywać informacje o wszystkich pikselach
na obrazie, sieć analizuje je przy użyciu filtrów konwolucyjnych.
Te wartości przesyłane są dalej do następnej warstwy.\\
Obecnie ten typ sieci odnosi największe osiągnięcia w dziedzinie rozpoznawania obrazów,
w wielu przypadkach dorównując lub nawet pokonując ludzkie wyniki.

\paragraph{Konwolucja} \mbox{}\\
Wymieniona wyżej konwolucja, inaczej splot, polega na złożeniu dwóch funkcji. W przypadku obrazów
jedna z tych funkcji to obraz, który ma rozmiary większe niż druga funkcja określana
mianem filtra konwolucyjnego. Zastosowanie splotu, w zależności od przypadku,
pozwala na rozmycie, wyostrzanie lub wydobycie głębi z danego obrazu \cite{konwolucja}.
Poniższy wzór \ref{eq:conv} przedstawia sposób obliczenia splotu dwóch funkcji.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation*}
h[m, n] = (f * g)[m, n] = \sum_j^m \sum_k^n f[j, k] * g[m-j, n-k] \\
\end{equation*}
\centering
\captionsetup{justification=centering,margin=1cm}
\caption{Splot funkcji. Funkcja \textit{f} to dwuwymiarowa macierz z pikselami obrazu. Funkcja \textit{g} to filtr. Funkcja \textit{h} to nowo otrzymany obraz.}
\label{eq:conv}
\end{figure}\\
Poniżej przedstawiono przykładowy obraz na wyjściu filtra konwolucyjnego (zob. rys. \ref{fig:filter_conv}):
\begin{figure}[h!]
\centering
\includegraphics[scale=1]{filter_conv}
\centering
\caption{Po lewej oryginalny obraz, po prawej na wyjściu filtra konwolucyjnego.}
\label{fig:filter_conv}
\end{figure}

\section{Warstwy sieci neuronowej}

W sieciach neuronowych wyróżniamy kilka rodzajów warstw, które poza wejściową i wyjściową,
można dobierać zależnie od sposobu rozwiązania danego problemu i typu posiadanych danych.

\paragraph{Wejściowa} \mbox{}\\
W sytuacji, gdy danymi jest zbiór obrazów, warstwa wejściowa ma rozmiar identyczny z
wymiarami obrazu.

\paragraph{Wyjściowa} \mbox{}\\
Rozmiar warstwy wyjściowej odpowiada ilości klas, do jakiej dane były rozdzielane.
W tej pracy, gdzie oczekiwanym wyjściem była liczba oczek możliwych do wyrzucenia na
kostce, odpowiada on 6 klasom. Wyjściem takiej sieci jest więc wektor o wymiarach 6x1.

\paragraph{Konwolucyjna} \mbox{}\\
Warstwa konwolucyjna służy do przetworzenia danych z poprzedniej warstwy przy użyciu
filtrów konwolucyjnych \cite{CS231n}. Filtry mają określone wymiary i służą do znajdowania cech
na obrazach lub ich fragmentach. Zastosowanie wielu warstw konwolucyjnych umożliwia filtrom
analizowanie bardziej złożonych zależności na obrazach.

\paragraph{W pełni połączona} \mbox{}\\
Najpopularniejszy typ warstwy to w pełni połączony \textit{(ang. Fully Connected, Dense)}.
Każdy neuron łączy się ze wszystkimi neuronami następnej warstwy, co skutkuje dużą ilością
potrzebnych do wykonania obliczeń.
W sieciach konwolucyjnych umieszczane są zwykle po warstwach konwolucyjnych
i służą do powiązania nieliniowych kombinacji.

\paragraph{Flatten} \mbox{}\\
Warstwa spłaszczająca \textit{(ang. Flatten)} stosowana jest w celu połączenia warstw
konwolucyjnych z warstwami w pełni połączonymi. Realizowane jest to poprzez przekształcenie
warstwy wejściowej do jednowymiarowego wektora, który następnie służy za wejście
do kolejnych warstw.

\paragraph{Odrzucająca} \mbox{}\\
Użycie warstwy odrzucającej \textit{(ang. Dropout)} jest jednym z najlepszych sposobów
na poradzenie sobie ze zjawiskiem przetrenowania, opisanym na końcu tego rozdziału
\cite{DropoutPreventOverfit}. Warstwa odrzucająca nie wykorzystuje wyjść pewnych neuronów,
co skutkuje rozpoznawaniem wyraźniejszych cech. W warstwie tej określamy prawdopodobieństwo,
z jakim neurony zostaną zachowane. Najczęściej stosuje się ją po warstwach w pełni
połączonych, zarówno przy przechodzeniu w przód, jak i tył \cite{DropConnect}.

\paragraph{Pooling} \mbox{}\\
Warstwa ta wykorzystywana jest do zmniejszenia rozmiaru pamięci oraz ilości obliczeń
w sieci neuronowej. Operacja polega na wybraniu jednego piksela z danego obszaru i przekazaniu
go do następnej warstwy. Najczęściej wykorzystywany jest tzw. MaxPooling, wybierający
piksel o największej wartości. Pooling nie zachowuje informacji o położeniu piksela przekazanego
na wyjście warstwy, co moze objawiać sie błędnymi interpretacjami przez sieci.

\section{Funkcje aktywacji}

Pomnożona suma wartości wejściowych i ich wag zostaje przekazana
jako argument do funkcji aktywacji, a obliczona wartości staje się wyjściem neuronu.
Wybór funkcji jest jednym z kluczowych parametrów danej sieci, ponieważ niewłaściwy wybór
może prowadzić do problemów podczas uczenia sieci \cite{activationFunctions, activationFunctionsV2}.

\paragraph{Sigmoid} \mbox{}\\
Sigmoid jest popularną funkcją aktywacji. Problemem z nią związanym
jest ryzyko zaniknięcia gradientu, co może prowadzić do problemu tzw. umierającego
neuronu. Występuje ono, gdy dla danej funkcji aktywacji,
gradient staje się bardzo mały, co jest równoznaczne z zaprzestaniem procesu uczenia.
W sigmoid gradient może zanikać obustronnie. Wzór funkcji sigmoidalnej pokazany jest poniżej \ref{eq:sigmoid}.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation*}
f(x) = \sigma(x) = \frac{1}{1 + e^{-x}} \\
\end{equation*}
\caption{Funkcja sigmoidalna}
\label{eq:sigmoid}
\end{figure}

\paragraph{ReLU} \mbox{}\\
ReLU \textit{(and. Rectified linear unit)} jest najpopularniejszą funkcją
aktywacji wykorzystywaną w sieciach neuronowych \cite{CS231n_activ, WIKIrectifier}.
Zasługą tego jest szybki czas uczenia sieci bez znaczącego kosztu w postaci generalizacji
dokładności. Problem z zanikającym gradientem jest mniejszy niż w przypadku funkcji
sigmoidalnej, ponieważ występuje on tylko z jednej strony.
Wzór \ref{eq:relu} na obliczenie ReLU przedstawiony jest poniżej.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation**}
f(x) = max(0, x)
\end{equation**}
\caption{ReLU - Rectified linear unit}
\label{eq:relu}
\end{figure}

\paragraph{LeakyReLU} \mbox{}\\
LeakyReLU jest ulepszeniem funkcji ReLU \cite{CS231n_activ} dzięki zastosowaniu niewielkiego
gradientu w sytuacji, dla której ReLU jest nieaktywne. Zmiana ta pozwala na uniknięcie
problemu znikającego gradientu. Jej wzór \ref{eq:leakyrelu} przedstawiony jest poniżej.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation*}
f(x) =
\begin{cases}
x & \text{if } x \geqslant 0 \\
0.01x & \text{if } x < 0 \\
\end{cases}
\end{equation*}
\caption{LeakyReLU}
\label{eq:leakyrelu}
\end{figure}

\paragraph{Softmax} \mbox{}\\
Softmax jest funkcją obliczającą rozkład prawdopodobieństwa wystąpienia danego zdarzenia.
Wykorzystywana jest w sytuacjach wymagających przyporządkowania
elementu do jednej z wielu klas. \\W tej pracy wykorzystywana jest w ostatniej warstwie do
przypisania ilości rozpoznanych oczek do każdego ze zdjęć. Wzór funkcji \ref{eq:softmax} zaprezentowany jest poniżej.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation*}
f(x_{i}) = \frac{e^{x_{i}}} {\sum_{j = 0}^{k}(e^{x_{j}})}
\end{equation*}
\caption{Funkcja softmax}
\label{eq:softmax}
\end{figure}

\section{Optymalizator}

Algorytmy optymalizacyjne wykorzystywane są do minimalizacji funkcji błędu poprzez
znajdowanie nowych wartości wag neuronów w sieci. Mają kluczowe
znaczenie podczas procesu uczenia sieci w kwestii czasu oraz skuteczności \cite{typesOfOptimizationAlgorithms}.

\paragraph{Współczynnik uczenia} \mbox{}\\
Do ustalenia z jakąś szybkością sieć neuronowa będzie dostosowywać się do danych, wykorzystujemy
współczynnik lub wskaźnik uczenia \textit{(ang. lerning rate)}. Wybranie zbyt małego
współczynnika wydłuży proces uczenia, a zbyt duża jego wartość może spowodować problemy
ze znalezieniem optymalnego rozwiązania. W niektórych algorytmach współczynnik uczenia
zmniejsza się w czasie, by lepiej dostosować się do danych i zniwelować oba wspomniane problemy.

\paragraph{Metoda największego spadku} \mbox{}\\
Metoda największego spadku \textit{(ang. Gradient Descent)} jest podstawowym algorytmem
służącym do zmiany wartości wag podczas procesu uczenia sieci.
Wadą tej metody jest przeprowadzanie jednorazowej aktualizacji po wyliczeniu gradientu dla
całego zestawu danych. Spowalnia to uczenie i może powodować problem z ilością zajmowanego
miejsca w pamięci. Sporą wadą jest możliwość doprowadzenia do stagnacji w jednym z
lokalnych minimów funkcji. Wzór \ref{eq:gradientdescent} znajduje się poniżej.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation*}
\theta = \theta - \eta * \nabla J(\theta)
\end{equation*}
\centering
gdzie: \texteta - współczynnik uczenia, \textit{J} - funkcja błedu
\caption{Metoda największego spadku}
\label{eq:gradientdescent}
\end{figure}\\

\paragraph{Stochastic gradient descent} \mbox{}\\
Stochastic gradient descent \textit{(skrót. SGD)} jest rozwinięciem metody największego spadku,
bardzo często wykorzystywaną w praktyce \cite{OptimizersOverview}.
Ulepszenie polega na obliczaniu gradientu dla jednego lub niewielkiej ilości przykładów
treningowych. SGD pozwala na lepsze dopasowanie
niż metoda gradientu prostego, ale wiąże się z koniecznością zastosowania mniejszego
współczynnika uczenia. Sposób obliczania SGD przedstawiony jest poniżej \ref{eq:sgd}.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation*}
\theta = \theta - \eta * \nabla J(\theta; x_i; y_i)
\end{equation*}
\centering
gdzie \texteta - współczynnik uczenia, \textit{J} - funkcja błedu,
\textit{x, y} - wejściowe i wyjściowe dane treningowe dla określonej iteracji
\caption{Stochastic gradient descent}
\label{eq:sgd}
\end{figure}

\paragraph{Adam} \mbox{}\\
Adam to skrót od angielskiej nazwy \textit{Adaptive Moment Estimation} i jest rozwinięciem
metody Stochastic Gradient Descent \cite{OptimizersOverview,AdamOptimizer}.
Metoda ta zapewnia dostosowanie współczynnika uczenia do każdego z parametrów z osobna,
korzystając przy tym z pierwszego i drugiego momentu centralnego, czyli odpowiednio ze
średniej oraz wariancji. Adam obecnie jest bardzo popularny z uwagi na szybkość działania
i osiąganie bardzo dobrych wyników. Poniższe wzory przedstawiają sposób na jego obliczenie \ref{eq:moments_adam}, \ref{eq:adam}.
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation*}
\begin{align*}
\hat{m_t} = \frac{m_t} {1 - \beta^t_1}, \\
\hat{v_t} = \frac{v_t} {1 - \beta^t_2}, \\
\end{align*}
\end{equation*}
\caption{Wzór na obliczanie pierwszego \textit{(m)} i drugiego \testit{(v)} momentu centralnego}
\label{eq:moments_adam}
\end{figure}
Obliczone momenty podstawiane są do wzoru
\begin{figure}[h!]
\renewcommand{\figurename}{Wzór}%
\begin{equation*}
\theta_{t+1} = \theta_t - \frac {\eta} {\sqrt{\hat{v_t}} + \epsilon} \hat{m_t}
\end{equation*}
\centering
gdzie najczęściej \textbeta \textsuperscript{t}\textsubscript{1} = 0.9 oraz
\textbeta \textsuperscript{t}\textsubscript{2} = 0.99 a \straightepsilon = 10^{-8}\\
\caption{Optymalizator Adam}
\label{eq:adam}
\end{figure}

\section{Przetrenowanie}
Zjawisko przetrenowania \textit{(ang. Overfitting)} polega na błędnym rozpoznawaniu nowych danych,
kiedy podczas treningu sieć uczyła się poprawnie. Może być ono bardzo trudne do wykrycia,
co powoduje, że jest jednym z największych problemów podczas pracy z sieciami neuronowymi.
Istnieje wiele sposobów na ograniczenie przetrenowania, a jedną z najlepszych technik
jest zastosowanie warstw odrzucających \cite{DropoutPreventOverfit}.

\section{Procesy}

\paragraph{Uczenie} \mbox{}\\
Uczenie bądź trening sieci jest procesem, w którym wagi sieci dostosowują się do dostarczonych danych.
Nauczona sieć powinna sprawnie realizować zamierzone zadanie, na przykład poprawnego
rozpoznawania ilości oczek wyrzuconych na kostce. Trening jest bardzo kosztowny obliczeniowo,
ponieważ operacje dodawania i mnożenia wektorów oraz macierzy wykonywane są miliony razy.

\paragraph{Testowanie} \mbox{}\\
Testowanie polega na porównaniu wyników dla zbioru testowego z oczekiwanymi wartościami.
Istotne jest, aby zbiór służący do testowania nie był wcześniej użyty do treningu sieci.
Nauczony model powinien być w stanie rozpoznawać nowe, nieużyte podczas procesu uczenia
dane i poprawnie je klasyfikować.

\paragraph{Predykcja} \mbox{}\\
Wartości zwrócone przez sieć po umieszczeniu w niej określonych danych nazywane są
predykcją. Pozwala to na wykorzystanie nauczonego modelu w praktycznym zastosowaniu.

\paragraph{Epoka} \mbox{}\\
Epoka nie zalicza się do procesów, ale jest bezpośrednio związana z procesem uczenia.
Jednorazowe przejście wszystkich elementów z treningowego zbioru danych nazywane jest epoką.
W praktycznym zastosowaniu ilość epok ustala się na co najmniej kilkanaście, chociaż w
wielu pracach naukowych przedstawiane są wyniki po 100 epokach treningu.

\section{Inne}
Poniżej przedstawiono dwa najbardziej rozpowszechnione zbiory danych do rozpoznawania obrazów.
Architektura pierwszej sieci bazowała na modelach służących do rozponawania tych zbiorów.

\paragraph{MNIST} \mbox{}\\
Baza danych MNIST \cite{MNIST} to zbiór 60000 treningowych i 10000 testowych czarno-białych obrazów
w rozmiarze 28x28x1, zawierających ręcznie napisane cyfry 0-9. Jest jednym z
najpopularniejszych zbiorów służących do rozpoczęcia nauki sztucznych sieci neuronowych
i uczenia maszynowego.

\paragraph{CIFAR-10} \mbox{}\\
Zbiór CIFAR-10 \cite{CIFAR-10} składa się z 50000 treningowych i 10000 testowych kolorowych obrazów w rozmiarze
32x32x2. Jest podzielony na 10 klas: samolot, samochód, ptak, kot, jeleń, pies, żaba,
koń, statek, ciężarówka; gdzie każdej z nich przypada po 6000 obrazów. Jest to podobnie
jak MNIST jeden z najbardziej popularnych zbiorów do uczenia maszynowego i sieci neuronowych.
