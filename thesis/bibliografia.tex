% !TEX encoding = UTF-8 Unicode
\addcontentsline{toc}{chapter}{Bibliografia}
\begin{thebibliography}{99}

\bibitem{CS231n}
Stanford University course CS231n
\\\texttt{http://cs231n.github.io/convolutional-networks/}

\bibitem{XORproblem}
Aditya V. D
\\\texttt{https://becominghuman.ai/neural-network-xor-application-and-fund\\amentals-6b1d539941ed}

\bibitem{NNbiology}
Eric Roberts, Stanford University
\\\texttt{https://cs.stanford.edu/people/eroberts/courses/soco/projects/\\neural-networks/}

\bibitem{CS231n_activ}
Stanford University course CS231n
\\\texttt{http://cs231n.github.io/neural-networks-1/}

\bibitem{NeuronAnimation}
Tuples Edu
\\\texttt{https://becominghuman.ai/what-is-an-artificial-neuron-8b2e421ce42e}

\bibitem{needForBias}
Jaron Collis
\\\texttt{https://medium.com/deeper-learning/glossary-of-deep-learning-bias\\-cf49d9c895e2}

\bibitem{substBigConv}
Leonardo Araujo dos Santos
\\\texttt{https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/\\content/convolutional\_neural\_networks.html}

\bibitem{whyNotMSE}
James D. McCaffrey
\\\texttt{https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use\\-cross-entropy-error-instead-of-classification-error-or-mean-squared-\\error-for-neural-network-classifier-training/}

\bibitem{CS231n_backprop}
Stanford University course CS231n
\\\texttt{http://cs231n.github.io/optimization-2/}

\bibitem{backprop}
Leonardo Araujo dos Santos
\\\texttt{https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/\\content/backpropagation.html}

\bibitem{intuitiveExplanation}
Ujjesl Karn
\\\texttt{https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/}

\bibitem{WIKIcnn}
\\\texttt{https://en.wikipedia.org/wiki/Convolutional\_neural\_network}

\bibitem{konwolucja}
Krzysztof Sopy≈Ça
\\\texttt{https://ksopyla.com/python/operacja-splotu-przetwarzanie-obrazow/}

\bibitem{DropoutPreventOverfit}
Jason Morrison
\\\texttt{https://medium.com/paper-club/paper-review-dropout-a-simple-way-\\to-prevent-neural-networks-from-overfitting-4f25e8f2283a}

\bibitem{DropConnect}
Li Wan, Matthew Zeiler, Sixin Zhang, Yann LeCun, Rob Fergus
\\\texttt{https://cs.nyu.edu/\char`\~wanli/dropc/}

\bibitem{activationFunctions}
Avinash Sharma V
\\\texttt{https://medium.com/the-theory-of-everything/understanding-activa\\tion-functions-in-neural-networks-9491262884e0}

\bibitem{activationFunctionsV2}
Sagar Sharma
\\\texttt{https://towardsdatascience.com/activation-functions-neural-netwo\\rks-1cbd9f8d91d6}

\bibitem{WIKIrectifier}
\\\texttt{https://en.wikipedia.org/wiki/Rectifier\_(neural\_networks)}

\bibitem{typesOfOptimizationAlgorithms}
Anish Singh Walia
\\\texttt{https://towardsdatascience.com/types-of-optimization-algorithms-\\used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f}

\bibitem{OptimizersOverview}
Sebatian Ruder
\\\texttt{http://ruder.io/optimizing-gradient-descent/}

\bibitem{AdamOptimizer}
Diederik P.Kingma, Jimmy Ba
\\\texttt{https://arxiv.org/abs/1412.6980}

\bibitem{MNIST}
Yann LeCun, Corinna Cortes, Christoper J.C. Burges
\\\texttt{http://yann.lecun.com/exdb/mnist/}

\bibitem{CIFAR-10}
Alex Krizhevsky
\\\texttt{https://www.cs.toronto.edu/\char`\~kriz/cifar.html}

\bibitem{AlexNetNVIDIA}
Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton
\\\texttt{https://www.nvidia.cn/content/tesla/pdf/machine-learning/imagenet-\\classification-with-deep-convolutional-nn.pdf}

\bibitem{AlexNetpresentation}
Tugce Tasci, Kyunghee Kim
\\\texttt{http://vision.stanford.edu/teaching/cs231b\_spring1415/slides/alex\\net\_tugce\_kyunghee.pdf}

\end{thebibliography}
