{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D convolution network with Adam optimizer (Functional model)\n",
    "\n",
    "\n",
    "\n",
    "## This notebook is based on idea of AlexNet, the winner of ILSVRC 2012 - The ImageNet Large Scale Visual Recognition Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['navyOnWhite', 'greenOnGreen', 'navyOnBlue', 'blackOnBlack', 'whiteOnBlue', 'blackOnRed', 'redOnRed', 'stainOnWhite', 'redOnRed_white', 'whiteOnBlack', 'hardLight', 'whiteOnRed', 'greenOnWhite', 'woodOnRed', 'whiteOnRed_distance']\n",
      "100800\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import backend as K\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from numpy.testing import assert_allclose, assert_equal\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# initialization and check if dataset got proper size\n",
    "\n",
    "# path = '/home/ubuntu/zdjecia/'\n",
    "path = '/Users/oziomek/licencjat/kostki/zdjecia/'\n",
    "listing = os.listdir(path)\n",
    "print(listing)\n",
    "num_samples = 0\n",
    "for folder in os.listdir(path):\n",
    "    for i in range(1, 7):\n",
    "        num_samples += len(os.listdir(path + folder + '/' + str(i)))\n",
    "assert_equal(100800, num_samples)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data into numpy array\n",
    "immatrix = np.array(\n",
    "    [np.array(Image.open(path + folder + '/' + str(i) + '/' + file)).flatten() \n",
    "         for folder in os.listdir(path)\n",
    "             for i in range(1, 7) \n",
    "                 for file in os.listdir(path + folder + '/' + str(i))], 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(immatrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.ones((num_samples, ), dtype=int)\n",
    "counter = 0\n",
    "for folder in os.listdir(path):\n",
    "    for i in range(1, 7):\n",
    "        samples = len(os.listdir(path + folder + '/' + str(i)))\n",
    "        labels[counter:counter+samples] = i-1\n",
    "        counter += samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize data with const random_state\n",
    "data, label = shuffle(immatrix, labels, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show randomly chosen image\n",
    "rows, cols = 64, 64\n",
    "labels_values = 6\n",
    "train_data = [data, label]\n",
    "import random\n",
    "for i in range(10):\n",
    "    random_image = random.randint(0, 100800)\n",
    "    img=immatrix[random_image].reshape(rows, cols)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print(\"There are {} dots, number is {}\".format(labels[random_image] + 1, random_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y) = (train_data[0], train_data[1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to [color_layers][pixels_height][pixels_width], color_layers equal to 2 because photos are in GRAYSCALE\n",
    "X_train = X_train.reshape(X_train.shape[0], rows, cols, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], rows, cols, 1).astype('float32')\n",
    "\n",
    "# normalize to 0-1\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot\n",
    "y_train = to_categorical(y_train, 6)\n",
    "y_test = to_categorical(y_test, 6)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create functional model with 2NN layers\n",
    "\n",
    "visible = Input(shape=(64, 64, 1))\n",
    "\n",
    "conv1 = Conv2D(96, kernel_size=11, padding='same', activation='relu')(visible)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "conv2 = Conv2D(256, kernel_size=5, padding='same', activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "dropout1 = Dropout(0.2)(pool2)\n",
    "conv3 = Conv2D(384, kernel_size=3, padding='same', activation='relu')(dropout1)\n",
    "conv4 = Conv2D(384, kernel_size=3, padding='same', activation='relu')(conv3)\n",
    "dropout2 = Dropout(0.2)(conv4)\n",
    "conv5 = Conv2D(256, kernel_size=3, padding='same', activation='relu')(dropout2)\n",
    "pool3 = MaxPooling2D((2, 2))(conv5)\n",
    "flat1 = Flatten()(pool3)\n",
    "hidden1 = Dense(2048, kernel_initializer='random_uniform', activation='relu')(flat1)\n",
    "dropout3 = Dropout(0.2)(hidden1)\n",
    "hidden2 = Dense(512, kernel_initializer='random_uniform', activation='relu')(dropout3)\n",
    "dropout4 = Dropout(0.2)(hidden2)\n",
    "hidden3 = Dense(128, kernel_initializer='random_uniform', activation='relu')(dropout4)\n",
    "predictions = Dense(6, activation='softmax')(hidden3)\n",
    "model = Model(inputs=visible, outputs=predictions)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 64, 64, 96)        11712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 16, 16, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 16, 16, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2048)              33556480  \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 38,395,974\n",
      "Trainable params: 38,395,974\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# summarize model and apply checkpoints\n",
    "print(model.summary())\n",
    "filepath = 'dice_AlexNet-{epoch:02d}-{loss:.4f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of a model\n",
    "plot_model(model, to_file='dice_AlexNet_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=25, batch_size=1024, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "print(\"Accuracy: %.2f%%\" % (score[1]*100))\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training results:')\n",
    "for i in range(len(model.metrics_names)):\n",
    "    print(str(model.metrics_names[i]) + \": \" + str(score[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('dice_AlexNet_model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights('dice_AlexNet_weights.h5')\n",
    "print('Saved model weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('model2-25-0.0074.h5')\n",
    "# check in models are similar to the given tolerance\n",
    "# assert_allclose(model.predict(X_train),\n",
    "#                new_model.predict(X_train),\n",
    "#                1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'model2API_continue-{epoch:02d}-{loss:.4f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_history = new_model.fit(X_train, y_train, epochs=10, batch_size=2048, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_score = new_model.evaluate(X_test, y_test, verbose=1)\n",
    "print('training results:')\n",
    "for i in range(len(new_model.metrics_names)):\n",
    "    print(str(new_model.metrics_names[i]) + \": \" + str(new_score[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('model2API_continue.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights('model2API_weights_continue.h5')\n",
    "print('Saved model weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
