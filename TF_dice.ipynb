{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN example as previous examples, this time using purely TensorFlow, without Keras overlay\n",
    "\n",
    "Troubles with spliting the data info batched with *TypeError* \"Unhashable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from numpy.testing import assert_equal\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['navyOnWhite', 'greenOnGreen', 'navyOnBlue', 'blackOnBlack', 'whiteOnBlue', 'blackOnRed', 'redOnRed', 'stainOnWhite', 'redOnRed_white', 'whiteOnBlack', 'hardLight', 'whiteOnRed', 'greenOnWhite', 'woodOnRed', 'whiteOnRed_distance']\n",
      "100800\n",
      "(100800, 4096)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "path = '/Users/oziomek/licencjat/kostki/zdjecia/'\n",
    "listing = os.listdir(path)\n",
    "print(listing)\n",
    "num_samples = 0\n",
    "for folder in os.listdir(path):\n",
    "    for i in range(1, 7):\n",
    "        num_samples += len(os.listdir(path + folder + '/' + str(i)))\n",
    "assert_equal(100800, num_samples)\n",
    "print(num_samples)\n",
    "\n",
    "data = np.array(\n",
    "    [np.array(Image.open(path + folder + '/' + str(i) + '/' + file)).flatten() \n",
    "         for folder in os.listdir(path)\n",
    "             for i in range(1, 7) \n",
    "                 for file in os.listdir(path + folder + '/' + str(i))], 'f')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(features, labels, mode):\n",
    "    \n",
    "    #input\n",
    "    input_layer = tf.reshape(features['x'], [-1, 64, 64, 1])\n",
    "    \n",
    "    #convolutional1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding='same',\n",
    "        activation='relu')\n",
    "    \n",
    "    #pooling1\n",
    "    pool1 = tf.layers.max_pooling2d(\n",
    "        inputs=conv1, \n",
    "        pool_size=[2, 2], \n",
    "        strides=1)\n",
    "    \n",
    "    #convolutional2\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding='same',\n",
    "        activation='relu')\n",
    "    \n",
    "    #dropout1\n",
    "    dropout1 = tf.layers.dropout(\n",
    "        inputs=conv2, \n",
    "        rate=0.2,\n",
    "        training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    #flatten1\n",
    "    flat1 = tf.reshape(\n",
    "        dropout1, \n",
    "        [-1, 32*32*64])\n",
    "    \n",
    "    #dense1\n",
    "    dense1 = tf.layers.dense(\n",
    "        inputs=flat1, \n",
    "        units=1024, \n",
    "        activation='relu')\n",
    "    \n",
    "    #dropout2\n",
    "    dropout2 = tf.layers.dropout(\n",
    "        inputs=dense1, \n",
    "        rate=0.2,\n",
    "        training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    #dense2\n",
    "    dense2 = tf.layers.dense(\n",
    "        inputs=dropout2, \n",
    "        units=256, \n",
    "        activation='relu')\n",
    "    \n",
    "    #dropout2\n",
    "    dropout3 = tf.layers.dropout(\n",
    "        inputs=dense2, \n",
    "        rate=0.2,\n",
    "        training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    #dense3\n",
    "    dense3 = tf.layers.dense(\n",
    "        inputs=dropout3, \n",
    "        units=64, \n",
    "        activation='relu')\n",
    "    \n",
    "    labeled = tf.layers.dense(\n",
    "        inputs=dense3,\n",
    "        units=6)\n",
    "    \n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=labeled, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(labeled, name='softmax_tensor')\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # for train and eval mode\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    # for train mode\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=0.001,\n",
    "            beta1=0.9,\n",
    "            beta2=0.999,\n",
    "            epsilon=1e-08,\n",
    "            use_locking=False,\n",
    "            name='Adam')\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    # for eval mode\n",
    "    eval_metrics_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(\n",
    "            labels=labels,\n",
    "            predictions=predictions['classes'])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metrics_ops=eval_metrics_ops)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(arg):\n",
    "    \n",
    "    labels = np.ones((num_samples, ), dtype=int)\n",
    "    counter = 0\n",
    "    for folder in os.listdir(path):\n",
    "        for i in range(1, 7):\n",
    "            samples = len(os.listdir(path + folder + '/' + str(i)))\n",
    "            labels[counter:counter+samples] = i-1\n",
    "            counter += samples\n",
    "            \n",
    "    rows, cols = 64, 64\n",
    "    labels_values = 6\n",
    "    train_data = [data, labels]\n",
    "    import random\n",
    "    for i in range(3):\n",
    "        random_image = random.randint(0, 100800)\n",
    "        img=data[random_image].reshape(rows, cols)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        print(\"There are {} dots, number is {}\".format(labels[random_image] + 1, random_image))\n",
    "        \n",
    "    (X, y) = (train_data[0], train_data[1])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], rows, cols, 1).astype('float32')\n",
    "    X_test = X_test.reshape(X_test.shape[0], rows, cols, 1).astype('float32')\n",
    "\n",
    "    # normalize to 0-1\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    \n",
    "    y_train = tf.one_hot(y_train, 6)\n",
    "    y_test = tf.one_hot(y_test, 6)\n",
    "    print(y_train.shape, y_test.shape)\n",
    "    \n",
    "    # Create the Estimator\n",
    "    dice_classifier = tf.estimator.Estimator(\n",
    "        model_fn=cnn_model, model_dir=\"/dice_convnet_model\")\n",
    "\n",
    "    # Set up logging for predictions\n",
    "    # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "        tensors=tensors_to_log, every_n_iter=5)\n",
    "    \n",
    "    # Train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": X_train},\n",
    "        y=y_train,\n",
    "        batch_size=512,\n",
    "        num_epochs=25,\n",
    "        shuffle=True)\n",
    "    dice_classifier.train(\n",
    "        input_fn=train_input_fn,\n",
    "        steps=20000,\n",
    "        hooks=[logging_hook])\n",
    "    \n",
    "    # Evaluate the model and print results\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": X_test},\n",
    "        y=y_test,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    eval_results = dice_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
